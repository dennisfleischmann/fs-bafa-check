



You said:
â€œHi, ich brauche jetzt einen AI-Agenten, der mir die BAFA-AntrÃ¤ge EinzelmaÃŸnahmen GebÃ¤udehÃ¼lle prÃ¼ft von meinen Kunden. Das heiÃŸt, Input ist eigentlich nur das Angebot und ich will rausfiltern, was fÃ¶rderfÃ¤hig ist und was nicht, dem Kunden dann eine Nachricht schicken.â€
00:30

ChatGPT said:
Das klingt machbar, aber ein bisschen Detailarbeit steckt drin. Dein AI-Agent mÃ¼sste die relevanten BAFA-Kriterien fÃ¼r EinzelmaÃŸnahmen (GebÃ¤udehÃ¼lle) kennen â€“ z.B. Mindest-U-Werte, fÃ¶rderfÃ¤hige Materialien, etc. Dann scannt er dein Angebot: Welche MaÃŸnahmen, welche Bauteile, welche Materialien sind drin? Der Agent vergleicht das mit den Vorgaben. Am Ende spuckt er eine klare Liste aus: "Diese Teile sind fÃ¶rderfÃ¤hig, diese nicht" â€“ und daraus kannst du dann dem Kunden eine Nachricht generieren. Mit ein bisschen Kontextwissen rund um die BAFA-Richtlinien und ein solides Parsing deines Angebots kriegen wir das gut hin. Ich wÃ¼rde auf jeden Fall mit klaren Kriterien starten und deine Angebote strukturiert halten, damit der Agent nicht raten muss.


You said:
â€œGenau, und dann ein Fallback, ein Sicherheitsmechanismus muss eingebaut werden. Wenn kein Kriterium zutrifft, muss der ein Abbruchkriterium haben.â€
00:13

ChatGPT said:
Absolut, ein Fallback ist super wichtig. Wenn das Angebot so schwammig wÃ¤re, dass gar kein Kriterium greift, muss der Agent klar abbrechen. Er kÃ¶nnte dann zum Beispiel eine Meldung generieren wie: â€Keine eindeutige FÃ¶rder


You said:
â€œJa, es gibt ja eine BEG-Anforderungsliste und die sagt ja ganz genau, unter welcher Bedingung etwas gefÃ¶rdert wird. Und dazu gibt es noch eine technische MaÃŸnahmenbeschreibung. Diese Kombination sagt recht prÃ¤zise, was fÃ¶rderfÃ¤hig ist und was nicht.â€
00:24

ChatGPT said:
Genau das ist der Punkt. Mit der BEG-Anforderungsliste und der technischen MaÃŸnahmenbeschreibung im RÃ¼cken hast du ja einen festen Rahmen. Der Agent gleicht dann die Bauteile, Materialien und Werte aus dem Angebot exakt damit ab. Und falls da irgendwas gar nicht ins Raster passt â€“ also weder fÃ¶rderfÃ¤hig noch Ã¼berhaupt sinnvoll bewertbar â€“ bricht er ab und liefert dir quasi eine â€KlÃ¤rung nÃ¶tigâ€œ-RÃ¼ckmeldung. Damit stellst du sicher, dass du nie halbgare Infos an den Kunden gibst, sondern genau weiÃŸt, wann du nachfassen musst.


You said:
â€œWas wÃ¼rdest du empfehlen? WÃ¼rde ich diese Anforderungsliste und technische MaÃŸnahmenbeschreibung vorher strukturieren oder sollte ich das immer abgleichen bei jedem Mal?â€
00:14

ChatGPT said:
Ich wÃ¼rde dir empfehlen, die Anforderungen vorab strukturiert zu hinterlegen. Wenn du die BEG-Kriterien und MaÃŸnahmenbeschreibungen in eine Art â€Nachschlagewerkâ€œ fÃ¼r deinen Agent packst, lÃ¤uft der Abgleich viel effizienter. Der Agent checkt dann jedes Mal gegen diese klare Datenbank, anstatt bei jeder PrÃ¼fung von Null zu starten. Das spart Zeit und sorgt fÃ¼r Konsistenz. Die Liste aktualisierst du dann einfach, wenn die FÃ¶rderbedingungen sich Ã¤ndern. So bist du immer auf der sicheren Seite.


You said:
â€œIch bin ich doch viel besser bedient, wenn er das immer abgleicht, oder? Wenn das Downloadbare, wenn das Referenzdokument, das aus dem Internet ist, dann holt er sich ja immer das Aktuelle und prÃ¼ft das dagegen.â€
00:19

ChatGPT said:
Ja, wenn du sicherstellen willst, dass wirklich immer der neueste Stand geprÃ¼ft wird, dann macht ein Live-Abgleich mit dem aktuellen Referenzdokument Sinn. Der Agent zieht sich dann direkt die frischeste Version und gleicht dein Angebot damit ab. Das hat den Vorteil, dass du nicht manuell nachpflegen musst und immer auf dem neuesten Stand bist. Klar, das macht jede PrÃ¼fung etwas dynamischer, aber fÃ¼r FÃ¶rderungen, wo sich die Vorgaben ja auch Ã¤ndern kÃ¶nnen, ist das ein ziemlich schlauer Weg. Du hast dann einfach die Sicherheit, dass du nie mit veralteten Kriterien arbeitest.


You said:
â€œNur der Large Language Model muss halt gut genug sein, um die Sachen dann zu analysieren, aber das macht ihr ja sowieso beim ersten Mal, dann kann das auch jedes Mal machen.â€
00:13

ChatGPT said:
Genau, das ist der springende Punkt. Solange dein Modell die Strukturen und Logik einmal gut verstanden hat, wird es das bei jeder PrÃ¼fung zuverlÃ¤ssig tun. Dann ist es egal, ob du einmal oder hundertmal abgleichst. Am Ende ist es ja das Ziel, dass dein Agent diese Anforderungslogik so verinnerlicht, dass du dich darauf verlassen kannst. Und dann lÃ¤uft das â€“ egal, wie oft sich die Richtlinien mal Ã¤ndern.


You said:
â€œDas heiÃŸt, der Input ist ein Angebot und der Output ist fÃ¼r meine SekretÃ¤rin eine Beschreibung, wieâ€
00:12

ChatGPT said:
Ganz genau. Du gibst das Angebot rein, der Agent filtert, was fÃ¶rderfÃ¤hig ist, und am Ende bekommt deine SekretÃ¤rin eine klare, strukturierte Beschreibung: Welche MaÃŸnahmen sind fÃ¶rderfÃ¤hig, welche nicht, und ob eventuell noch Infos fehlen. Das ist dann quasi ein kurzes, verstÃ¤ndliches Memo, mit dem sie den Kunden direkt informieren oder nachfassen kann. So spart ihr euch langes manuelles PrÃ¼fen und habt sofort eine klare Antwort.


You said:
â€œJa, vor allen Dingen auch, ich brauche keinen externen Partner, die das fÃ¼r teuer Geld machen. Das ist halt auch wichtig.â€
00:07

ChatGPT said:
Absolut, so hÃ¤ltst du die Kontrolle in-house und sparst dir diese externen Kosten. Einmal gut aufgesetzt, arbeitet der Agent rund um die Uhr, immer nach den aktuellen Regeln, und du kannst dich auf prÃ¤zise, schnelle Ergebnisse verlassen â€“ ganz ohne extra Rechnungen.


You said:
â€œGenau, und dann macht sie zehn am Tag.â€
00:02

ChatGPT said:
Ganz genau, und wenn das dann jeden Tag lÃ¤uft, hast du am Ende eine Routine, die sich richtig bezahlt macht. Kein lÃ¤stiges Warten, keine Unsicherheit â€“ einfach saubere, verlÃ¤ssliche Ergebnisse, Tag fÃ¼r Tag.


You said:
Also ich hÃ¤tte folgendes gesasgt

1.) Unterlagen gibt es immer 



https://www.bafa.de/DE/Energie/Effiziente_Gebaeude/Foerderprogramm_im_Ueberblick/foerderprogramm_im_ueberblick_node.html



<div class="togglewrapper tabmodul gsb-toggle">
  
<ul class="tabs-list" role="tablist"><li><a href="#" class="switch-panel0 active-control" aria-selected="true" tabindex="0" role="tab" id="_gj1gqltgd" aria-controls="_jvutn1lbp">Publikationen</a></li><li><a href="#" class="switch-panel1 inactive-control" aria-selected="false" tabindex="-1" role="tab" id="_hqgqld2su" aria-controls="_5sctyl45z">Rechtsgrundlagen</a></li><li><a href="#" class="switch-panel2 inactive-control" aria-selected="false" tabindex="-1" role="tab" id="_qydivq2tp" aria-controls="_ddvh4ngb7">Zum Thema</a></li>
  </ul>
<div class="tabs-container"><h3 class="heading active-control"><button aria-expanded="true" id="_xs97ecic6" aria-controls="_jvutn1lbp">Publikationen</button></h3>
<div class="switch-panel0 panel-opened" role="region" id="_jvutn1lbp" aria-labelledby="_gj1gqltgd" style="display: block;">
    
<ul class="links"><li class="download"><a href="/SharedDocs/Downloads/DE/Energie/beg_merkblatt_allgemein_antragstellung.pdf?__blob=publicationFile&amp;v=10" title="Ã–ffnet im neuen Fenster" target="_blank" class="downloadLink">Allgemeines Merkblatt zur Antragstellung (Februar 2025)&nbsp;(PDF, 539KB, Datei ist nicht barrierefrei)</a></li><li class="download"><a href="/SharedDocs/Downloads/DE/Energie/beg_merkblatt_allgemein_zusatzantrag.pdf?__blob=publicationFile&amp;v=3" title="Ã–ffnet im neuen Fenster" target="_blank" class="downloadLink">Allgemeines Merkblatt zum Zusatzantrag fÃ¼r den Einkommensbonus&nbsp;(PDF, 474KB, Datei ist nicht barrierefrei)</a></li><li class="download"><a href="/SharedDocs/Downloads/DE/Energie/beg_infoblatt_foerderfaehige_kosten.pdf?__blob=publicationFile&amp;v=12" title="Ã–ffnet im neuen Fenster" target="_blank" class="downloadLink">Infoblatt zu den fÃ¶rderfÃ¤higen MaÃŸnahmen und Leistungen â€“ Sanieren&nbsp;(PDF, 817KB, Datei ist nicht barrierefrei)</a></li><li class="download"><a href="/SharedDocs/Downloads/DE/Energie/beg_merkblatt_antragstellung_wnet_gnet.pdf?__blob=publicationFile&amp;v=20" title="Ã–ffnet im neuen Fenster" target="_blank" class="downloadLink">Merkblatt zur Antragstellung fÃ¼r die Errichtung, Umbau und Erweiterung eines GebÃ¤udenetzes und fÃ¼r den Anschluss an ein neu zu errichtendes GebÃ¤udenetz&nbsp;(PDF, 1MB, Datei ist nicht barrierefrei)</a></li><li class="download"><a href="/SharedDocs/Downloads/DE/Energie/beg_checkliste_gleichwertigkeit.pdf?__blob=publicationFile&amp;v=2" title="Ã–ffnet im neuen Fenster" target="_blank" class="downloadLink">Anforderungen zur Anerkennung gleichwertiger Verfahren des hydraulischen Abgleichs zum Verfahren B in der <abbr title="BundesfÃ¶rderung fÃ¼r effiziente GebÃ¤ude">BEG</abbr>&nbsp;(PDF, 121KB, Datei ist nicht barrierefrei)</a></li>
    </ul>
</div><h3 class="heading inactive-control"><button aria-expanded="false" id="_t81gvej62" aria-controls="_5sctyl45z">Rechtsgrundlagen</button></h3>
<div class="switch-panel1 panel-closed" role="region" id="_5sctyl45z" aria-labelledby="_hqgqld2su" style="display: none;" hidden="hidden">
    
<ul class="links"><li class="download"><a href="/SharedDocs/Downloads/DE/Energie/beg_richtline_beg_em_20231221_PDF.pdf?__blob=publicationFile&amp;v=2" title="Ã–ffnet im neuen Fenster" target="_blank" class="downloadLink">Richtlinie fÃ¼r die BundesfÃ¶rderung fÃ¼r effiziente GebÃ¤ude â€“ EinzelmaÃŸnahmen (<abbr title="BundesfÃ¶rderung fÃ¼r effiziente GebÃ¤ude - EinzelmaÃŸnahmen">BEG EM</abbr>) vom 21. Dezember 2023 (Fundstelle: <abbr title="Bundesanzeiger">BAnz</abbr> <abbr title="Amtlicher Teil">AT</abbr> 29.12.2023 B1)&nbsp;(PDF, 2MB, Datei ist nicht barrierefrei)</a></li>
    </ul>
</div><h3 class="heading inactive-control"><button aria-expanded="false" id="_a4zywbvhb" aria-controls="_ddvh4ngb7">Zum Thema</button></h3>
<div class="switch-panel2 panel-closed" role="region" id="_ddvh4ngb7" aria-labelledby="_qydivq2tp" style="display: none;" hidden="hidden">
    
<ul class="links"><li><a href="https://www.energiewechsel.de/KAENEF/Redaktion/DE/FAQ/FAQ-Uebersicht/BEG/faq-bundesfoerderung-fuer-effiziente-gebaeude.html" class="external" title="Externer Link:&nbsp;Antworten auf hÃ¤ufig gestellte Fragen zur BEG (FAQ) (Ã–ffnet&nbsp;neues&nbsp;Fenster)" target="_blank" rel="noopener noreferrer">Antworten auf hÃ¤ufig gestellte Fragen zur <abbr title="BundesfÃ¶rderung fÃ¼r effiziente GebÃ¤ude">BEG</abbr> (<abbr title="frequently asked questions"><abbr title="frequently asked questions">FAQ</abbr></abbr>)</a></li><li class="download"><a href="/SharedDocs/Downloads/DE/Energie/beg_em_foerderuebersicht.pdf?__blob=publicationFile&amp;v=13" title="Ã–ffnet im neuen Fenster" target="_blank" class="downloadLink">FÃ¶rderÃ¼bersicht: BundesfÃ¶rderung fÃ¼r effiziente GebÃ¤ude â€“ EinzelmaÃŸnahmen&nbsp;(PDF, 70KB, Datei ist nicht barrierefrei)</a></li><li><a href="https://www.energie-effizienz-experten.de/fileadmin/user_upload/Qualifizierte_Expertenliste_Landingpage/Medienbereich/Grafik-Foerderung-BEG-1.png" class="external" title="Externer Link:&nbsp;Welche FÃ¶rderungen gibt es und wohin wende ich mich? (Ã–ffnet&nbsp;neues&nbsp;Fenster)" target="_blank" rel="noopener noreferrer">Welche FÃ¶rderungen gibt es und wohin wende ich mich?</a></li><li><a href="https://www.energie-effizienz-experten.de/fileadmin/user_upload/Qualifizierte_Expertenliste_Landingpage/Medienbereich/Grafik-Foerderung-BEG-2.png" class="external" title="Externer Link:&nbsp;Wo bekomme ich welche FÃ¶rderung?  (Ã–ffnet&nbsp;neues&nbsp;Fenster)" target="_blank" rel="noopener noreferrer">Wo bekomme ich welche FÃ¶rderung?</a></li><li><a href="https://www.energie-effizienz-experten.de/fileadmin/user_upload/Qualifizierte_Expertenliste_Landingpage/Medienbereich/Grafik-Foerderung-BEG-3.png" class="external" title="Externer Link:&nbsp;WÃ¤rme- und GebÃ¤udenetze â€“ Was sind die Unterschiede? (Ã–ffnet&nbsp;neues&nbsp;Fenster)" target="_blank" rel="noopener noreferrer">WÃ¤rme- und GebÃ¤udenetze â€“ Was sind die Unterschiede?</a></li>
    </ul>
</div></div>
</div>



jeden Morgen geht der Agent durch und downlaodet alle Informationen neu 

1.Frage an dich. In welcher Form sollte alles abgelegt werden

Neue Struktur/Context fÃ¼r den AI Agent?

ChatGPT said:
Sehr gute Richtung. ğŸ‘
Kurzfassung vorweg: Ja, neue Struktur + klarer Kontext fÃ¼r den AI-Agent ist zwingend notwendig â€“ aber nicht als â€reiner TextmÃ¼llâ€œ, sondern als versionierte, maschinenlesbare Wissensbasis mit harten Regeln + Abbruchlogik.

Ich empfehle dir eine 3-Schichten-Architektur, die genau zu deinem Use-Case (BAFA BEG EM GebÃ¤udehÃ¼lle, 10 PrÃ¼fungen/Tag, SekretÃ¤rin-Output) passt.

1ï¸âƒ£ Grundsatz-Entscheidung (wichtig)
âŒ Nicht empfehlenswert

Jedes Mal PDFs â€rohâ€œ analysieren

LLM frei interpretieren lassen (â€versteht schonâ€œ)

FÃ¶rderlogik nur implizit im Prompt

âœ… Empfehlenswert

Einmal strukturieren â†’ tÃ¤glich aktualisieren

Trennung von Recht, Technik und Entscheidungslogik

Explizite Abbruchkriterien (Fail-Safe)

2ï¸âƒ£ Zielbild: Wie denkt dein AI-Agent?
Der Agent soll nicht kreativ denken, sondern prÃ¼fend entscheiden:

â€Ich darf nur dann fÃ¶rderfÃ¤hig = JA sagen,
wenn alle Muss-Kriterien explizit erfÃ¼llt sind.
Wenn nicht â†’ Abbruch / KlÃ¤rung.â€œ

Das erreichst du nur mit strukturierter Referenzlogik.

3ï¸âƒ£ Empfohlene Struktur (Best Practice)
ğŸ”¹ Ebene A â€“ â€Source Layerâ€œ (tÃ¤glich aktualisiert)
Zweck: Rechtssicherheit & AktualitÃ¤t

Was hier liegt:

Offizielle PDFs von Bundesamt fÃ¼r Wirtschaft und Ausfuhrkontrolle (BAFA)

BEG EM Richtlinie

Infoblatt fÃ¶rderfÃ¤hige MaÃŸnahmen

Technische Mindestanforderungen

MerkblÃ¤tter Antragstellung

Metadaten:

Quelle

Datum

Version

URL

GÃ¼ltig_ab

ğŸ‘‰ Format:

Original: PDF (unverÃ¤ndert, revisionssicher)

ZusÃ¤tzlich: Text-Extrakt (Markdown oder TXT)

âš ï¸ Wichtig:
Diese Ebene wird nicht direkt vom LLM interpretiert, sondern dient als juristische Referenz.

ğŸ”¹ Ebene B â€“ â€Normierte Wissensbasisâ€œ (entscheidend!)
Zweck: Maschinell prÃ¼fbare Regeln

Hier passiert die Magie.

âœ… Format: JSON oder YAML (kein Freitext)
Beispiel (vereinfacht):

{
  "bauteil": "AuÃŸenwand",
  "maÃŸnahme": "WÃ¤rmedÃ¤mmung",
  "fÃ¶rderfÃ¤hig": true,
  "muss_kriterien": {
    "u_wert_max": 0.20,
    "dÃ¤mmstoff_erlaubt": ["EPS", "XPS", "MW", "Holzfaser"],
    "mind_dÃ¤mmstÃ¤rke_cm": 10,
    "bestandsgebÃ¤ude": true
  },
  "ausschluss": [
    "InnendÃ¤mmung ohne Tauwassernachweis",
    "DÃ¤mmung < MindeststÃ¤rke"
  ],
  "quelle": "BEG EM TMA GebÃ¤udehÃ¼lle 2025-02"
}
ğŸ‘‰ Vorteil:

deterministisch

auditierbar

versionierbar

LLM wird PrÃ¼fer, nicht Entscheider

ğŸ”¹ Ebene C â€“ â€Decision Engine / Prompt Contextâ€œ
Zweck: klare Logik + Fallback

Hier definierst du unverrÃ¼ckbare Regeln, z. B.:

ğŸ”’ Entscheidungslogik (Pflicht!)
Wenn Muss-Kriterium fehlt â†’ NICHT fÃ¶rderfÃ¤hig

Wenn Wert nicht explizit genannt â†’ KLÃ„RUNGSFALL

Wenn MaÃŸnahme nicht eindeutig zuordenbar â†’ ABBRUCH

Keine Annahmen, keine SchÃ¤tzungen

Beispiel Abbruchregel:

Wenn aus dem Angebot weder
- Bauteil
- MaÃŸnahme
- DÃ¤mmstoff
- Kennwert (z. B. U-Wert oder Dicke)
eindeutig hervorgehen,
darf keine FÃ¶rderfÃ¤higkeit bestÃ¤tigt werden.
4ï¸âƒ£ Input â†’ Output (fÃ¼r deine SekretÃ¤rin)
ğŸ“¥ Input
Angebot (PDF, DOCX, Text)

optional: Herstellerdatenblatt

âš™ï¸ Verarbeitung
Angebot strukturieren (Bauteil â†’ MaÃŸnahme â†’ Werte)

Abgleich gegen Ebene B

Entscheidung nach Ebene C

ğŸ“¤ Output (standardisiert!)
Beispiel:

Ergebnis BAFA-PrÃ¼fung â€“ GebÃ¤udehÃ¼lle

âœ… FÃ¶rderfÃ¤hig:
- AuÃŸenwanddÃ¤mmung EPS 14 cm
  â†’ U-Wert rechnerisch â‰¤ 0,20 W/mÂ²K

âŒ Nicht fÃ¶rderfÃ¤hig:
- Kellerdecke: DÃ¤mmstÃ¤rke nicht angegeben

âš ï¸ KlÃ¤rungsbedarf:
- Dach: DÃ¤mmstoff nicht spezifiziert
â¡ï¸ Direkt per Mail an Kunden nutzbar

5ï¸âƒ£ Deine konkrete Frage â€“ klare Antwort
â€In welcher Form sollte alles abgelegt werden?â€œ

âœ… Meine Empfehlung (final):
Ebene	Format	Zweck
Source	PDF + TXT	Recht & Nachweis
Wissensbasis	JSON / YAML	FÃ¶rderlogik
Agent Context	Prompt + Regeln	Sicherheit
Logs	JSON	Nachvollziehbarkeit
Nicht: Word, Notion, reiner Prompt, Copy-Paste-PDFs

6ï¸âƒ£ NÃ¤chster sinnvoller Schritt (empfohlen)
Wenn du willst, machen wir als NÃ¤chstes:

konkretes JSON-Schema fÃ¼r BEG EM GebÃ¤udehÃ¼lle

Abbruch- & Eskalationsmatrix

fixes Prompt-Template fÃ¼r deinen Agenten

Mail-Vorlagen fÃ¼r deine SekretÃ¤rin

Sag mir einfach, womit wir starten sollen.


You said:
{
  "bauteil": "AuÃŸenwand",
  "maÃŸnahme": "WÃ¤rmedÃ¤mmung",
  "fÃ¶rderfÃ¤hig": true,
  "muss_kriterien": {
    "u_wert_max": 0.20,
    "dÃ¤mmstoff_erlaubt": ["EPS", "XPS", "MW", "Holzfaser"],
    "mind_dÃ¤mmstÃ¤rke_cm": 10,
    "bestandsgebÃ¤ude": true
  },
  "ausschluss": [
    "InnendÃ¤mmung ohne Tauwassernachweis",
    "DÃ¤mmung < MindeststÃ¤rke"
  ],
  "quelle": "BEG EM TMA GebÃ¤udehÃ¼lle 2025-02"
}

bekommt man dieses Format immer hin?

Was ist wenn LLM ein fehler macht?

ChatGPT said:
Ja â€“ man bekommt dieses Format sehr zuverlÃ¤ssig hin, aber nicht, indem man â€nurâ€œ ein LLM bittet, JSON zu schreiben. Du baust es so, dass ein Fehler entweder gar nicht mÃ¶glich ist oder automatisch abgefangen wird.

Hier ist das robuste Setup, das ich dir empfehlen wÃ¼rde (praxisnah, 10+/Tag tauglich):

1) â€œImmer hinbekommenâ€: JSON erzwingen statt hoffen
âœ… A) Striktes JSON-Schema + Validator
Du definierst ein JSON Schema (Pflichtfelder, Datentypen, erlaubte Werte, Zahlenbereiche).

Wenn das LLM â€Quatschâ€œ ausgibt â†’ Validator schlÃ¤gt fehl

Dann greift dein Fallback (Abbruch / KlÃ¤rungsfall)

Ergebnis: Nie geht falsches Format an deine SekretÃ¤rin raus

Beispiel-Validierungen

u_wert_max muss Zahl sein

dÃ¤mmstoff_erlaubt nur aus Whitelist

fÃ¶rderfÃ¤hig nur true/false

bauteil nur aus kontrollierter Liste (AuÃŸenwand, Dach, Kellerdecke, Fenster â€¦)

âœ… B) â€œFunction calling / structured outputsâ€
Wenn du ein Modell/Framework nutzt, das Structured Output kann, lÃ¤sst du das Modell gar nicht â€frei textenâ€œ, sondern es muss in das Schema passen. Sonst kommt keine Antwort bzw. ein Fehler â†’ Fallback.

âœ… C) Zwei-Phasen Output (sehr stark)
Phase 1: Extraktion aus Angebot â†’ neutrales, faktisches JSON (ohne Bewertung)

Phase 2: Regel-Engine prÃ¼ft gegen deine Wissensbasis â†’ FÃ¶rderstatus

Damit trennst du:

â€Was steht im Angebot?â€œ (Extraction)

â€Ist es fÃ¶rderfÃ¤hig?â€œ (Decision)

Das reduziert Halluzinationen massiv.

2) â€œWas, wenn das LLM einen Fehler macht?â€
Das ist die wichtigste Frage. LÃ¶sung: LLM darf nie final entscheiden, sondern nur liefern, was danach geprÃ¼ft wird.

Sicherheitsnetz 1: â€œNo-Guess Policyâ€
Hard rule:

Wenn ein Muss-Wert fehlt (U-Wert / Dicke / Material / Bauteil) â†’ nicht bewerten, sondern KLÃ„RUNG.

Das ist dein Abbruchkriterium.

Sicherheitsnetz 2: Evidence-Links (Zitatpflicht)
Der Agent muss fÃ¼r jedes extrahierte Feld die Textstelle aus dem Angebot mitgeben:

"u_wert": {
  "value": 0.19,
  "evidence": "AuÃŸenwand: U = 0,19 W/mÂ²K"
}
Wenn evidence fehlt â†’ Feld gilt als â€nicht vorhandenâ€œ â†’ KlÃ¤rungsfall.

Sicherheitsnetz 3: Regel-Engine statt LLM-Logik
Die Entscheidung â€fÃ¶rderfÃ¤hig ja/neinâ€œ wird deterministisch berechnet:

LLM extrahiert nur Fakten

Code prÃ¼ft Regeln (u_wert <= max, dÃ¤mmstoff in whitelist, etc.)

Sicherheitsnetz 4: Cross-Check / Second pass (optional, aber effektiv)
Ein zweites, gÃ¼nstiges Modell oder derselbe Agent:

prÃ¼ft: â€Sind alle Muss-Kriterien wirklich belegt?â€œ

wenn Widerspruch â†’ KlÃ¤rungsfall

Sicherheitsnetz 5: Risiko-Scoring
Du gibst jedem Fall einen Score:

0.0 = sicher

1.0 = unsicher / missing fields

Ab einem Schwellenwert (z. B. 0.3) wird automatisch abgebrochen.

3) Realistische Erwartung: Wo passieren Fehler?
Angebote sind unprÃ¤zise

â€DÃ¤mmung gemÃ¤ÃŸ GEGâ€œ â†’ nicht prÃ¼fbar
â¡ï¸ KlÃ¤rung statt Entscheidung

Bauteil-Zuordnung

â€Fassadeâ€œ kann AuÃŸenwand oder WDVS sein
â¡ï¸ Nur freigeben, wenn eindeutig

Technische Nachweise

InnendÃ¤mmung braucht Tauwassernachweis
â¡ï¸ Wenn nicht erwÃ¤hnt â†’ Ausschluss/ KlÃ¤rung

4) Der beste Kompromiss fÃ¼r dich (Kosten/Nutzen)
Wenn du 10 PrÃ¼fungen/Tag willst, wÃ¼rde ich so bauen:

Pipeline

Angebots-Text â†’ Extraktions-JSON (mit Evidence)

JSON Schema Validation (hart)

Decision Engine (harte Regeln)

Output: SekretÃ¤rinnen-Memo + Kundenmail-Entwurf

Wenn irgendwas fehlt/unklar: â€œKlÃ¤rungs-Checklisteâ€ statt Ergebnis

Das ist schnell, skalierbar und â€LLM-fehlerresistentâ€œ.

Wenn du willst, schreibe ich dir als nÃ¤chstes:

ein konkretes JSON-Schema (fÃ¼r GebÃ¤udehÃ¼lle)

die Abbruchlogik als Regeln

und ein Output-Template fÃ¼r deine SekretÃ¤rin (inkl. Textbausteinen fÃ¼r Kunden).


You said:
ÃœberprÃ¼fe deinen Ansatz und schaue konkret an schwachstellen

ChatGPT said:

Thought for 18s
Alles klar â€“ ich zerlege meinen Ansatz jetzt hart und nenne dir die konkreten Schwachstellen (inkl. wie du sie entschÃ¤rfst). Wichtig: JSON-Schema + Validator schÃ¼tzt nur das Format, nicht die Richtigkeit.

1) Schwachstelle: â€œImmer aktuellâ€ durch tÃ¤gliches Downloaden ist nicht automatisch â€œimmer korrektâ€
Problem:

BAFA-Seiten Ã¤ndern PDFs/Versionen manchmal ohne klare Semantik (z. B. neue v=13), Links kÃ¶nnen brechen, Inhalte kÃ¶nnen sich innerhalb eines Tages Ã¤ndern.

Wenn dein Agent um 8:00 Uhr lÃ¤dt und um 14:00 Uhr prÃ¼ft, kann es Versionsdrift geben (unterschiedliche Mitarbeiter/PrÃ¼fungen basieren auf verschiedenen StÃ¤nden).

HÃ¤rtung:

Pinning je PrÃ¼flauf: Jede PrÃ¼fung lÃ¤uft gegen eine konkrete Version (Hash + Datum + URL).

Update-Fenster + Freigabe: Updates tÃ¤glich laden, aber erst nach kurzem â€œSmoke-Testâ€ aktiv schalten.

Ergebnis-Memo enthÃ¤lt: â€œGeprÃ¼ft gegen: Dokument X, Version/Hash, Abrufdatum.â€

2) Schwachstelle: PDF-Text ist oft kaputt (und das killt â€œEvidenceâ€)
Problem:

Viele BAFA-PDFs sind ok, aber Kundenangebote sind hÃ¤ufig:

gescannt (Bild-PDF) â†’ OCR nÃ¶tig

Tabellen/Positionslisten â†’ Textreihenfolge zerhackt

Trennstriche, ZeilenumbrÃ¼che, Einheiten springen

Das fÃ¼hrt dazu, dass dein Agent falsche Werte â€œfindetâ€ oder Belege falsch zuordnet.

HÃ¤rtung:

Vorverarbeitung: â€œTextqualitÃ¤t-Checkâ€ (ist es Bild-PDF? sind Zahlen/WÃ¤hrungen sauber extrahierbar?).

Tabellenmodus: Wenn Angebot tabellarisch ist: erst Tabellenstruktur extrahieren (oder zumindest Position/Spalte).

Evidence muss Position/Zeile/Seite haben (Seitenzahl + Textsnippet). Wenn nicht â†’ â€œnicht belegbarâ€.

3) Schwachstelle: Das LLM kann Werte â€œglattziehenâ€ (Halluzination / ErgÃ¤nzung)
Problem:
Selbst mit Evidence kann es passieren:

â€œ14 cmâ€ wird aus â€œ140 mmâ€

â€œMW 035â€ wird zu â€œWLS 035â€

â€œU â‰¤ 0,20â€ wird als â€œU = 0,20â€ gelesen

Oder es ergÃ¤nzt fehlende Infos (â€œwird schon BestandsgebÃ¤ude seinâ€).

HÃ¤rtung:

No-Guess-Regel absolut: Keine Annahmen, keine Implikationen.

Einheiten-Normalisierung mit PlausibilitÃ¤tsregeln:
z. B. DÃ¤mmstÃ¤rke 2â€“40 cm plausibel; U-Werte 0,10â€“2,0 plausibel; alles auÃŸerhalb â†’ KlÃ¤rung.

Zahlen nur Ã¼bernehmen, wenn sie â€œnumerischâ€ + Einheit + Evidence haben.

4) Schwachstelle: â€œWhitelist DÃ¤mmstoffeâ€ ist zu grob/gefÃ¤hrlich
Problem:
Dein Beispiel ["EPS","XPS","MW","Holzfaser"] ist in der RealitÃ¤t zu kurz:

Angebote enthalten Handelsnamen, AbkÃ¼rzungen, Mischangaben (â€œResolâ€, â€œPU/PIRâ€, â€œPURâ€, â€œPhenolharzâ€, â€œCalciumsilikatâ€, â€œAerogelâ€ â€¦)

AuÃŸerdem ist â€œMaterial erlaubtâ€ selten das einzige Kriterium â€“ oft gehtâ€™s um Anwendungsfall / Nachweis / AusfÃ¼hrung.

HÃ¤rtung:

Statt Whitelist: Mapping-Layer (Synonyme/Handelsnamen â†’ Materialklasse).

Und: Material darf nicht allein Ã¼ber FÃ¶rderfÃ¤higkeit entscheiden. Es ist nur ein Parameter.

5) Schwachstelle: BAFA-Logik ist nicht rein â€œU-Wert â‰¤ Xâ€
Problem:
GebÃ¤udehÃ¼lle hat hÃ¤ufig Zusatzbedingungen:

InnendÃ¤mmung â†’ Tauwassernachweis / Feuchteschutz

Denkmalschutz/bauliche EinschrÃ¤nkungen â†’ SonderfÃ¤lle

Bauteildefinitionen sind tricky (AuÃŸenwand vs. Fassade/WDVS, Dach vs. oberste Geschossdecke etc.)

â€œFenster/TÃ¼renâ€ haben eigene Logik (Uw vs Ug, Einbau, Randverbund etc.)

HÃ¤rtung:

Bauteil-Taxonomie + MaÃŸnahmen-Typen als kontrolliertes Vokabular.

Regeln pro MaÃŸnahme-Typ, nicht nur pro Bauteil.

Jede Regel hat: required fields â†’ wenn eins fehlt, kein Urteil.

6) Schwachstelle: Angebotspositionen sind oft â€œLeistungspaketeâ€
Problem:
Ein Angebot kann â€œFassade komplettâ€ enthalten, inkl. GerÃ¼st, Putz, Anstrich, FensterbÃ¤nke etc.
Der Agent muss trennen:

fÃ¶rderfÃ¤hige Kostenbestandteile vs. nicht fÃ¶rderfÃ¤hige

HÃ¤rtung:

Output nicht nur â€œfÃ¶rderfÃ¤hig ja/neinâ€, sondern Kostenbestandteile clustern:

âœ… fÃ¶rderfÃ¤hig

âš ï¸ nur anteilig / abhÃ¤ngig

âŒ nicht fÃ¶rderfÃ¤hig / Nebenleistung

Wenn keine saubere Trennung mÃ¶glich â†’ â€œKlÃ¤rung: Positionen detaillierenâ€.

7) Schwachstelle: Format-Validierung â‰  Inhalts-Validierung
Problem:
Das LLM kann perfektes JSON liefern und trotzdem falsche Schlussfolgerungen ziehen.

HÃ¤rtung (entscheidend):

LLM nur fÃ¼r Extraktion, Entscheidung macht deterministische Rule Engine.

LLM-Ausgabe enthÃ¤lt keinen finalen FÃ¶rderstatus, nur â€œFacts + Evidenceâ€.

Rule Engine berechnet Status + BegrÃ¼ndung.

8) Schwachstelle: â€œSecond passâ€ mit LLM ist kein echtes Sicherheitsnetz
Problem:
Zwei Modelle kÃ¶nnen denselben Fehler wiederholen (gleiche SchwÃ¤che, gleiche Daten).

HÃ¤rtung:

Second pass muss anderer Typ PrÃ¼fung sein:

â€œStimmt Evidence wirklich?â€ (string match / page reference check)

â€œSind required fields vollstÃ¤ndig?â€ (programmatic)

â€œWidersprechen sich Werte?â€ (programmatic)

9) Schwachstelle: Abbruchkriterium kann zu oft triggern (Operativ nervig)
Problem:
Wenn du zu streng bist, hast du stÃ¤ndig â€œKlÃ¤rung nÃ¶tigâ€ â†’ SekretÃ¤rin verliert Zeit.

HÃ¤rtung:

Definiere 2 Modi:

Kundenmodus (streng): nur sichere Aussagen raus

Internmodus (hilfreich): â€œwahrscheinlich fÃ¶rderfÃ¤hig, ABER fehlt Xâ€ â€“ nur intern, nicht an Kunde

ZusÃ¤tzlich: â€œMinimalanforderungen pro MaÃŸnahmeâ€ so wÃ¤hlen, dass 80% der Angebote durchgehen.

10) Schwachstelle: Haftungs-/Kommunikationsrisiko
Problem:
Wenn der Agent dem Kunden â€œfÃ¶rderfÃ¤higâ€ schreibt und es stimmt nicht â†’ Ã„rger, Reklamation, ggf. Schadenersatz-Argumentation.

HÃ¤rtung:

Kundenmail immer mit Scope-Satz:

â€œVorprÃ¼fung auf Basis der im Angebot genannten Angaben. Finale PrÃ¼fung erfolgt im Rahmen der Antragstellung / technische Nachweise vorbehalten.â€

Und: Bei â€œgrÃ¼nem Ergebnisâ€ trotzdem: â€œerforderliche Nachweise/Unterlagenâ€ listen.

11) Schwachstelle: Monitoring/Regression fehlt (typischer Killer im Betrieb)
Problem:
Wenn BAFA-Doku sich Ã¤ndert oder Angebote anders aussehen, driftet dein System und du merkst es zu spÃ¤t.

HÃ¤rtung:

Baue einen Testkorpus (z. B. 50 typische Angebote) + erwartete Ergebnisse

TÃ¤glicher â€œRegression Runâ€ nach Update der Referenzdokumente

Logging: Welche Regeln feuern wie oft? Welche AbbrÃ¼che warum?

12) Schwachstelle: Datenschutz / Zugriff auf Kundendokumente
Problem:
Kundenangebote enthalten personenbezogene Daten. Je nach Setup (Cloud/LLM/API) hast du DSGVO-Themen.

HÃ¤rtung:

PII-Redaction vor LLM (Namen/Adresse/Telefon/IBAN etc.)

Oder â€œon-prem / EU-Hostâ€ je nach Infrastruktur

Speichere nur: Extraktionsdaten + Hash + Evidence-Ausschnitte (minimieren)

Fazit: Die 3 grÃ¶ÃŸten echten Schwachstellen
Wenn ich priorisieren mÃ¼sste:

PDF/Text-Extraktion (Tabellen/OCR/Evidence)

LLM macht plausible, aber falsche ErgÃ¤nzungen (No-Guess + required fields)

Regellogik/Taxonomie ist komplexer als â€œU-Wert â‰¤ Xâ€ (Rule Engine + MaÃŸnahmentypen)

Wenn du willst, mache ich dir als nÃ¤chsten Schritt ein konkretes, praxistaugliches â€œFacts-JSONâ€ Schema (Extraction-only) fÃ¼r GebÃ¤udehÃ¼lle â€“ inkl. required fields je MaÃŸnahme + Abbruchmatrix. Damit wird das System deutlich robuster als dein Beispiel-JSON, weil es Fehlerquellen systematisch ausschaltet.


You said:
Erstelle mir eine Logik um aus folgenden Dateien:


Allgemeines Merkblatt zur Antragstellung (Februar 2025) (PDF, 539KB, Datei ist nicht barrierefrei)
Allgemeines Merkblatt zum Zusatzantrag fÃ¼r den Einkommensbonus (PDF, 474KB, Datei ist nicht barrierefrei)
Infoblatt zu den fÃ¶rderfÃ¤higen MaÃŸnahmen und Leistungen â€“ Sanieren (PDF, 817KB, Datei ist nicht barrierefrei)
Merkblatt zur Antragstellung fÃ¼r die Errichtung, Umbau und Erweiterung eines GebÃ¤udenetzes und fÃ¼r den Anschluss an ein neu zu errichtendes GebÃ¤udenetz (PDF, 1MB, Datei ist nicht barrierefrei)
Anforderungen zur Anerkennung gleichwertiger Verfahren des hydraulischen Abgleichs zum Verfahren B in der BEG (PDF, 121KB, Datei ist nicht barrierefrei)
Richtlinie fÃ¼r die BundesfÃ¶rderung fÃ¼r effiziente GebÃ¤ude â€“ EinzelmaÃŸnahmen (BEG EM) vom 21. Dezember 2023 (Fundstelle: BAnz AT 29.12.2023 B1) (PDF, 2MB, Datei ist nicht barrierefrei)


PDF/Text-Extraktion (Tabellen/OCR/Evidence)

ein Format zu extrahieren fÃ¼r die Entscheidungsgrundlage von FÃ¶rderfÃ¤higkeiten

ChatGPT said:

Thought for 2m 54s
Unten ist eine praxistaugliche â€Extraktions- & Regel-Logikâ€œ, mit der du aus genau diesen PDFs eine maschinenlesbare Entscheidungsgrundlage (Ruleset) erzeugst â€“ inkl. Tabellen/OCR/Evidence und einem Sicherheitsmechanismus gegen LLM-Fehler.

1) Grundprinzip: Quelle â†’ Evidence â†’ Regel â†’ Validierung
Quellenrollen (wichtig fÃ¼r PrioritÃ¤t)
Normativ/maÃŸgeblich: BEG-EM-Richtlinie inkl. Anlage â€Technische Mindestanforderungen (TMA)â€. Dort stehen u. a. die U-Wert-Grenzen tabellarisch fÃ¼r GebÃ¤udehÃ¼lle. 

Operativ/auslegungsnah: MerkblÃ¤tter & Infoblatt (z. B. â€Infoblatt fÃ¶rderfÃ¤hige MaÃŸnahmen/Kostenâ€œ) â€“ hilfreich fÃ¼r Kostenabgrenzung & Prozess, aber i. d. R. nachrangig gegenÃ¼ber der Richtlinie (steht auch so im Merkblatt). 

Konsequenz: Regeln immer mit Evidence aus der Richtlinie/TMA verankern; Infoblatt ergÃ¤nzt â€fÃ¶rderfÃ¤hige Kosten / nicht fÃ¶rderfÃ¤hige Kostenâ€œ. Das Infoblatt ist explizit zur Ermittlung der fÃ¶rderfÃ¤higen Kosten (TPB/TPN/BzA/BnD) gedacht und wird regelmÃ¤ÃŸig aktualisiert. 

2) Ziel-Format (Ruleset) â€“ robust gegen Halluzinationen
Dein JSON-Beispiel ist vom Stil her gut, aber: â€dÃ¤mmstoff_erlaubtâ€œ ist oft nicht normativ (in TMA stehen eher Umax / Î»-Grenzen / Bauteilgruppen / SonderfÃ¤lle, nicht â€Material-Whitelistâ€œ). Besser ist ein Schema, das nur das extrahiert, was im Evidence wirklich steht.

Empfohlenes Datenmodell (minimal & â€LLM-sicherâ€œ)
{
  "ruleset_meta": {
    "program": "BEG EM",
    "generated_at": "2026-02-15T09:30:00Z",
    "documents": [
      {"doc_id":"beg_em_richtlinie_2023-12-21","version_hint":"BAnz AT 29.12.2023 B1","sha256":"..."},
      {"doc_id":"infoblatt_foerderfaehige_kosten","version_hint":"10.0 (07/2025)","sha256":"..."}
    ]
  },
  "rules": [
    {
      "rule_id": "tma_1.1_aussenwand_uaussenwand_wg_t>=19",
      "scope": {
        "module": "GebÃ¤udehÃ¼lle",
        "measure": "AuÃŸenwÃ¤nde",
        "component": "AuÃŸenwand"
      },
      "decision": "ELIGIBLE_IF",
      "conditions": [
        {"field":"building.is_existing", "op":"==", "value": true},
        {"field":"offer.component_type", "op":"==", "value":"AuÃŸenwand"},
        {"field":"target_zone", "op":"==", "value":"WG_or_NWG_zone_T>=19"},
        {"field":"offer.u_value", "op":"<=", "value": 0.20, "unit":"W/(mÂ²K)"}
      ],
      "requirements_text": [
        "WÃ¤rmebrÃ¼ckenreduzierte und luftdichte AusfÃ¼hrung beachten",
        "Feuchteschutz/Tauwasserschutz prÃ¼fen"
      ],
      "evidence": [
        {
          "doc_id":"beg_em_richtlinie_2023-12-21",
          "page": 18,
          "type":"table_row",
          "quote":"AuÃŸenwand 0,20",
          "bbox": [0.0, 0.0, 0.0, 0.0]
        }
      ],
      "confidence": "high"
    }
  ]
}
Warum das besser ist:

Jede Zahl/Schwelle ist evidence-gebunden (Seite + Tabellenzeile).

Du kannst automatisiert prÃ¼fen: Kommt â€0,20â€œ im Evidence-Text/Screenshot wirklich vor? â†’ wenn nein: Abbruch.

Beispiel-Evidence: In der TMA-Tabelle stehen die Umax-Grenzen fÃ¼r AuÃŸenwÃ¤nde (z. B. AuÃŸenwand 0,20 / 0,25 je Zone) direkt tabellarisch. 

AuÃŸerdem ist klar geregelt, dass GebÃ¤udehÃ¼llen-EinzelmaÃŸnahmen BestandsgebÃ¤ude betreffen. 

3) Extraktions-Logik (PDF â†’ Text/Tabelle/OCR â†’ â€Rule Candidatesâ€œ)
Schritt A â€“ Dokument-Manifest & Versionierung (tÃ¤glich)
Download PDFs

Speichere pro PDF:

source_url, download_date

sha256 (Datei-Hash)

doc_title, version_hint (z. B. Infoblatt â€Version 10.0 (07/2025)â€œ) 

Wenn sha256 unverÃ¤ndert â†’ kein Re-Extract nÃ¶tig (spart Zeit)

Hinweis: Die BAFA-Dokumente betonen explizit â€nur aktuelle Fassung gÃ¼ltigâ€œ und listen VersionsstÃ¤nde. 

Schritt B â€“ â€Born-digitalâ€œ Text & Layout ziehen
Versuche zuerst Layout-Text-Extraktion (koordinatenbasiert):

Output: lines[] mit page, x0,y0,x1,y1, text

QualitÃ¤tscheck:

text_coverage_ratio (z. B. Zeichen pro Seite)

Wenn sehr niedrig â†’ OCR-Fallback

Schritt C â€“ Tabellenextraktion (kritisch bei TMA)
FÃ¼r Seiten mit Tabellen (z. B. TMA U-Wert-Tabelle):

Tabellenregionen detektieren (bbox), notfalls per Bildanalyse

Extrahiere Tabellenzellen (Grid) â†’ cells[r][c]

Normalisiere:

Dezimal-Komma â†’ Dezimalpunkt (aber speichere Original â€0,20â€œ im Evidence!)

Units separat (W/(mÂ²K), W/(mÂ·K))

Genau diese Seite ist â€Table-firstâ€œ und muss stabil extrahiert werden, weil hier die Grenzwerte stehen. 

Schritt D â€“ OCR nur, wenn nÃ¶tig
OCR pro Seite nur bei:

gescannten Seiten

kaputter Tabellenextraktion

Output muss ebenfalls Bounding-Boxes liefern, sonst ist Evidence spÃ¤ter zu schwach.

4) Regel-Extraktion (LLM) â€“ aber nicht â€free styleâ€œ
LLM nur fÃ¼r:
Zuordnung: welche Tabellenzeile gehÃ¶rt zu welchem Bauteil / welcher Zone / welcher MaÃŸnahme

Extraktion von Textanforderungen (â€Feuchteschutz prÃ¼fenâ€¦â€œ) aus FlieÃŸtext

LLM nicht fÃ¼r:
â€Zahlen ratenâ€œ (Umax etc.)

â€Materiallisten erfindenâ€œ

â€FÃ¶rderlogik frei interpretierenâ€œ

Denn: In der TMA steht z. B. explizit auch der Hinweis, dass bei MaÃŸnahmen an der GebÃ¤udehÃ¼lle Feuchteschutz/Tauwasserschutz zu prÃ¼fen ist â€“ das ist Textlogik, dafÃ¼r ist LLM gut. 

5) Sicherheitsmechanismus (dein â€Abbruchkriteriumâ€œ gegen LLM-Fehler)
Hard Guards (automatisiert, deterministisch)
JSON-Schema Validation

Pflichtfelder vorhanden? Datentypen korrekt?

Evidence-Binding Check

Jede Zahl/Schwelle muss im Evidence-quote vorkommen

quote muss aus extrahiertem Text oder OCR stammen

Coverage Check

FÃ¼r jedes Modul (z. B. GebÃ¤udehÃ¼lle) mÃ¼ssen Mindest-Regeln existieren:

AuÃŸenwÃ¤nde, DachflÃ¤chen, Decken/BodenflÃ¤chen, Fenster/TÃ¼ren, sommerlicher WÃ¤rmeschutz (steht so als Kapitelstruktur im Infoblatt). 

Fehlt ein Bereich â†’ â€Ruleset incompleteâ€œ â†’ Abbruch

Diff-Alarm bei Updates

Wenn sich Grenzwerte Ã¤ndern (z. B. Umax), dann:

nicht automatisch live schalten

â€needs human reviewâ€œ

Soft Guards (im Ergebnis)
Output fÃ¼r SekretÃ¤rin/Kunde nur, wenn:

confidence != low

keine â€unknownâ€œ-Felder in SchlÃ¼sselparametern (z. B. U-Wert fehlt)

Sonst: â€Bitte manuell prÃ¼fen â€“ Angebot unvollstÃ¤ndig oder Regel nicht eindeutig belegbarâ€œ

6) Was du am Ende wirklich â€ablÃ¤gstâ€œ
Empfehlung: Speichere 2 Artefakte:

ruleset.json (entscheidungsrelevante Regeln + Evidence-Refs)

evidence_store (Textchunks + Tabellen + OCR + Screenshots mit bbox)

So kann dein PrÃ¼f-Agent spÃ¤ter zu jeder Entscheidung sagen:

â€Welche Regel hat gegriffen?â€œ

â€Wo steht das?â€œ (Dokument, Seite, Ausschnitt)

Wenn du willst, kann ich dir als nÃ¤chsten Schritt:

ein konkretes JSON-Schema (Draft 2020-12) fÃ¼r diese Rules bauen,

plus ein Mapping-Modell â€Angebot â†’ MaÃŸnahmenobjekteâ€œ, damit deine Angebotsanalyse sauber an die TMA-Regeln andockt (z. B. AuÃŸenwand / Dach / Fenster mit U-Wert, Zone, Denkmal-Flag etc.).


You said:
Reichen die conditions aus oder muss noch eine Beschreibung "Beispiel" fÃ¶rderfÃ¤hig, Beispiel nicht fÃ¶rderfÃ¤hig?

ChatGPT said:

Thought for 4 seconds
Die Conditions sind fÃ¼r die Maschinen-Entscheidung grundsÃ¤tzlich ausreichend â€“ wenn sie alle Muss-Infos abdecken und du eine harte No-Guess-Policy hast.

Aber: FÃ¼r Betriebssicherheit, Schulung deiner SekretÃ¤rin und Debugging empfehle ich zusÃ¤tzlich eine separate â€œGuidance/Examplesâ€-Ebene. Nicht als Pflicht fÃ¼r die Entscheidung, sondern als Hilfstext + TestfÃ¤lle.

Warum Conditions allein oft nicht reichen (praktisch)
Angebote sind unvollstÃ¤ndig/uneindeutig â†’ du brauchst â€œKlÃ¤rungs-Triggerâ€

SonderfÃ¤lle (InnendÃ¤mmung, Denkmalschutz, Anschlussdetails) â†’ schneller erkennbar mit Beispielen

QualitÃ¤tssicherung: Beispiele werden zu Regression-Tests, damit Updates nicht heimlich Fehler einfÃ¼hren

Best Practice: 3 Ebenen pro Regel
1) Decision (hart, deterministisch)
conditions[] + required_fields[] + abort_if_missing[]

Nur das entscheidet.

2) Guidance (weich, fÃ¼r Menschen & LLM-Interpretation)
kurze BegrÃ¼ndung, typische Stolperfallen, Hinweise auf Nachweise

3) Examples (Testkorpus, nicht â€œRechtstextâ€)
Beispiel fÃ¶rderfÃ¤hig / nicht fÃ¶rderfÃ¤hig / KlÃ¤rungsfall

idealerweise als kleine, synthetische â€œOffer-Factsâ€-Objekte (nicht ganze Angebote)

Konkrete Empfehlung fÃ¼r dein Schema
Erweitere die Regel so:

{
  "rule_id": "tma_aussenwand",
  "required_fields": ["offer.component_type","offer.u_value","building.is_existing","target_zone"],
  "abort_if_missing": ["offer.u_value","target_zone"],
  "conditions": [
    {"field":"building.is_existing","op":"==","value":true},
    {"field":"offer.component_type","op":"==","value":"AuÃŸenwand"},
    {"field":"offer.u_value","op":"<=","value":0.20,"unit":"W/(mÂ²K)"}
  ],
  "guidance": {
    "notes": [
      "Keine Annahmen: U-Wert muss im Angebot/Anlage explizit angegeben sein.",
      "Bei InnendÃ¤mmung ggf. Tauwassernachweis erforderlich (falls MaÃŸnahme InnendÃ¤mmung)."
    ],
    "clarification_questions": [
      "Bitte U-Wert-Nachweis oder DÃ¤mmaufbau/Î»+StÃ¤rke nachreichen.",
      "Handelt es sich um AuÃŸen- oder InnendÃ¤mmung?"
    ]
  },
  "examples": {
    "eligible": [
      {
        "facts": {"building.is_existing":true,"offer.component_type":"AuÃŸenwand","target_zone":"WG_T>=19","offer.u_value":0.19},
        "expected":"ELIGIBLE"
      }
    ],
    "not_eligible": [
      {
        "facts": {"building.is_existing":true,"offer.component_type":"AuÃŸenwand","target_zone":"WG_T>=19","offer.u_value":0.27},
        "expected":"NOT_ELIGIBLE"
      }
    ],
    "needs_clarification": [
      {
        "facts": {"building.is_existing":true,"offer.component_type":"AuÃŸenwand","target_zone":"WG_T>=19"},
        "expected":"ABORT_MISSING_FIELD:offer.u_value"
      }
    ]
  }
}
Wichtig: Beispiele sind nicht â€rechtlich bindendâ€œ
Beispiele dÃ¼rfen nie die Quelle ersetzen.

Sie dienen als Kommunikationshilfe + automatisierter Test (Regression), damit dein System stabil bleibt.

Meine klare Empfehlung
âœ… Conditions + required/abort sind Pflicht.
âœ… Examples sind sehr sinnvoll â€“ aber als separater Block (Guidance/Test), nicht als Entscheidungsbasis.

Wenn du willst, baue ich dir als NÃ¤chstes eine Standard-Rule-Template (fÃ¼r AuÃŸenwand, Dach, oberste Geschossdecke/Kellerdecke, Fenster/TÃ¼ren) inkl. Required Fields + KlÃ¤rungsfragen â€“ dann kannst du das 1:1 auf alle GebÃ¤udehÃ¼lle-MaÃŸnahmen skalieren.


You said:
 {"field":"offer.u_value","op":"<=","value":0.20,"unit":"W/(mÂ²K)"}

was ist damit?

ChatGPT said:

Thought for 14s
Das ist eine einzelne PrÃ¼fregel (Condition) in deiner Entscheidungs-Engine â€“ konkret:

{"field":"offer.u_value","op":"<=","value":0.20,"unit":"W/(mÂ²K)"}
Was bedeutet das?
offer.u_value = der U-Wert, der im Angebot/Anlage genannt ist (ideal: U-Wert nach MaÃŸnahme, also Ziel-/Endwert).

op:"<=" = Vergleichsoperator â€kleiner oder gleichâ€œ.

value:0.20 = der Grenzwert aus der TMA (Beispielwert).

unit:"W/(mÂ²K)" = Einheit (Watt pro Quadratmeter-Kelvin).

â¡ï¸ Entscheidung: Nur wenn der extrahierte U-Wert aus dem Angebot â‰¤ 0,20 W/(mÂ²K) ist, erfÃ¼llt die MaÃŸnahme dieses Kriterium.

Das Problem an der Stelle (und wie duâ€™s richtig machst)
1) Welcher U-Wert ist gemeint?
In Angeboten tauchen gerne mehrere Werte auf:

Bestand (vorher)

nach Sanierung / Zielwert (nachher)

rechnerische Werte aus einem Aufbau

âœ… LÃ¶sung: speichere getrennt:

offer.u_value_existing (optional)

offer.u_value_target (Pflicht fÃ¼r Entscheidung)

Und die Regel sollte auf offer.u_value_target gehen.

2) Woher kommt offer.u_value Ã¼berhaupt?
Der Wert muss aus dem Angebot extrahiert werden â€“ mit Evidence:

Textstelle â€U = 0,19 W/mÂ²Kâ€œ

oder Anlage/Produktblatt

oder â€DÃ¤mmung 160 mm WLS 035, U nach Sanierung â€¦â€œ

âœ… Wenn kein U-Wert explizit drinsteht:

nicht schÃ¤tzen

â†’ KlÃ¤rungsfall (â€Bitte U-Wert-Nachweis oder Aufbau/Î»+d nachreichenâ€œ)

3) Einheit / Schreibweisen
Im echten Leben steht das z. B. so:

W/mÂ²K, W/(mÂ²K), W/(mÂ²Â·K)

Dezimalkomma: 0,20

âœ… LÃ¶sung: Normalisierung im Parser:

0,20 â†’ 0.20

Einheitenvarianten â†’ canonical W/(mÂ²K)

4) Grenzwert hÃ¤ngt oft vom Kontext ab (Zone/Bauteil)
Der Grenzwert 0.20 ist nicht universell, sondern abhÃ¤ngig von:

Bauteil (AuÃŸenwand/Dach/Kellerdeckeâ€¦)

ggf. Temperatur-/Nutzungszone (beheizt/unbeheizt)

ggf. Sonderfall (InnendÃ¤mmung etc.)

âœ… LÃ¶sung: Grenzwert nicht â€hartâ€œ in die Condition schreiben, sondern als Referenz:

value_from: "tma.u_max" plus scope (Bauteil + Zone)

Dann zieht die Engine den richtigen Grenzwert aus deinem Ruleset.

Empfehlung: so sieht die â€œsaubereâ€ Condition aus
{
  "field":"offer.u_value_target",
  "op":"<=",
  "value_from":"rules.tma.u_max",
  "unit":"W/(mÂ²K)"
}
Und die Engine setzt rules.tma.u_max automatisch passend zu Bauteil/Zone.

Wenn du mir sagst, ob du U-Werte immer im Angebot stehen hast oder oft nur Aufbauten (Î» + d), dann gebe ich dir die beste Extraktionslogik (inkl. â€wann berechnen erlaubt istâ€œ vs. â€immer KlÃ¤rungâ€œ).


You said:
es kann beides vorkommen.

Fenster => immer Uw 
Dach => meistens dachaufbau + lambda
Wand => (Entweder der KUnde wÃ¼nscht sich die DÃ¤mmstÃ¤rke, oder es ist bereits vorgegeben, aber da muss nochmal geprÃ¼ft werden was der Kunde fÃ¼r ein Wandaufbau hat

ChatGPT said:

Thought for 1m 5s
Perfekt â€“ dann brauchst du eine â€Dual-Inputâ€œ-Logik:
(A) U-Wert direkt Ã¼bernehmen oder (B) U-Wert deterministisch aus Aufbau (d + Î») berechnen â€“ und bei WÃ¤nden zusÃ¤tzlich eine Worst-Case-Garantie, falls der Bestand unbekannt ist.

Unten ist eine praxistaugliche Logik, die mit deinen 3 FÃ¤llen (Fenster/Dach/Wand) sauber funktioniert.

1) Einheitliches â€Offer-Factsâ€œ-Format (Extraktionsergebnis)
Jede MaÃŸnahme wird als Objekt abgelegt:

component_type: Fenster | Dach | AuÃŸenwand | Kellerdecke | â€¦

input_mode: direct_u | layers

values: extrahierte Werte (inkl. Evidence)

calc: Ergebnis der Berechnung (falls layers)

decision: PASS | FAIL | CLARIFY (inkl. BegrÃ¼ndung + Fragen)

Minimal-Beispiel (vereinfacht):

{
  "component_type": "Dach",
  "input_mode": "layers",
  "layers": [
    {"name":"ZwischensparrendÃ¤mmung", "d_m":0.16, "lambda":0.035, "evidence":"..."},
    {"name":"AufsparrendÃ¤mmung", "d_m":0.10, "lambda":0.044, "evidence":"..."}
  ],
  "geometry": {"wood_fraction": null, "evidence": null},
  "calc": {"u_value_target": null, "method": null},
  "decision": {"status":"CLARIFY", "reason":"Holzanteil/Sparren unbekannt"}
}
2) Entscheidungs-Logik pro Bauteil
A) Fenster (bei dir â€immer Uwâ€œ)
Regel:

Wenn Uw im Angebot/Produktblatt explizit vorhanden â†’ verwenden (mit Evidence).

Wenn nur Ug oder â€3-fachâ€œ ohne Uw â†’ CLARIFY (nicht schÃ¤tzen).

Wenn mehrere Uw (z. B. unterschiedliche Fenster) â†’ pro Position separat.

Abbruchfelder (Pflicht):

Uw + Einheit

Zuordnung: welches Fenster zu welcher Position

KlÃ¤rungsfrage:

â€Bitte Uw je Fenstertyp/Position nachreichen (nicht nur Ug).â€œ

B) Dach (meist Aufbau + Î»)
Hier gibtâ€™s zwei UnterfÃ¤lle:

B1) Reine AufsparrendÃ¤mmung / homogene Schichten
Dann kannst du direkt rechnen:

R
=
R
s
i
+
âˆ‘
(
d
/
Î»
)
+
R
s
e
R=R 
si
â€‹
 +âˆ‘(d/Î»)+R 
se
â€‹
 

U
=
1
/
R
U=1/R

Hard Rule: Nur rechnen, wenn d und Î» pro Schicht vorliegen (Evidence).

B2) Zwischensparren (Parallelpfad: Holz + DÃ¤mmung)
Dann brauchst du den Holzanteil f (Sparrenanteil).

Berechnung (sicher & standardnah):

Pfad DÃ¤mmung: 
U
i
n
s
=
1
/
(
R
s
i
+
R
l
a
y
e
r
s
(
i
n
s
)
+
R
s
e
)
U 
ins
â€‹
 =1/(R 
si
â€‹
 +R 
layers(ins)
â€‹
 +R 
se
â€‹
 )

Pfad Holz: 
U
w
o
o
d
=
1
/
(
R
s
i
+
R
l
a
y
e
r
s
(
w
o
o
d
)
+
R
s
e
)
U 
wood
â€‹
 =1/(R 
si
â€‹
 +R 
layers(wood)
â€‹
 +R 
se
â€‹
 )

Gesamt: 
U
=
f
â‹…
U
w
o
o
d
+
(
1
âˆ’
f
)
â‹…
U
i
n
s
U=fâ‹…U 
wood
â€‹
 +(1âˆ’f)â‹…U 
ins
â€‹
 

Wenn f fehlt (hÃ¤ufig):

Nicht raten.

Aber du kannst eine Bandbreite bilden, die dir eine sichere Entscheidung erlaubt:

Bandbreiten-Logik

Rechne mit f=0.07, 0.10, 0.15 (wie du es kennst).

Wenn selbst bei 0.15 der Grenzwert eingehalten wird â†’ PASS (konservativ).

Wenn schon bei 0.07 gerissen wird â†’ FAIL.

Dazwischen â†’ CLARIFY (Sparrenbreite/Abstand/Holzanteil anfragen).

KlÃ¤rungsfragen (bei CLARIFY):

Sparrenbreite (cm), Sparrenabstand (AchsmaÃŸ), SparrenhÃ¶he / DÃ¤mmstÃ¤rke

Ist zusÃ¤tzlich AufsparrendÃ¤mmung vorhanden (reduziert HolzbrÃ¼ckeneffekt)?

C) AuÃŸenwand (Bestand oft unklar)
Das ist der kritischste Teil â€“ aber du kannst es trotzdem stabil bauen.

C1) U-Wert ist angegeben
â†’ direkt verwenden (wie Fenster), Evidence Pflicht.

C2) Nur neue DÃ¤mmung (Dicke + Î»), Bestand unbekannt
Hier empfehle ich eine Worst-Case-Garantie ohne Bestandswissen:

Worst-Case-U ohne Bestand

Setze den Bestandswiderstand konservativ = 0 (du ignorierst ihn komplett).

Dann gilt:
U
u
p
p
e
r
=
1
/
(
R
s
i
+
âˆ‘
(
d
n
e
u
/
Î»
n
e
u
)
+
R
s
e
)
U 
upper
â€‹
 =1/(R 
si
â€‹
 +âˆ‘(d 
neu
â€‹
 /Î» 
neu
â€‹
 )+R 
se
â€‹
 )

Warum das gut ist:
Der echte Bestand hat immer einen Widerstand > 0 â†’ der echte U-Wert ist besser (kleiner) als dein Worst-Case.
â¡ï¸ Wenn Worst-Case bereits â‰¤ Grenzwert ist, bist du sicher PASS, ohne Wandaufbau zu kennen.

Entscheidungslogik

Wenn U_upper â‰¤ Grenzwert â†’ PASS (garantiert)

Wenn U_upper > Grenzwert â†’ CLARIFY (dann brauchst du Bestandsinfos oder mehr DÃ¤mmung)

Was du bei Wand zusÃ¤tzlich abfragen musst (fÃ¼r CLARIFY / SonderfÃ¤lle):

InnendÃ¤mmung? â†’ Feuchte-/Tauwassernachweis erforderlich â†’ ohne Nachweis CLARIFY (nicht automatisch FAIL)

Materialkennwert fehlt (nur â€œ14 cm WDVSâ€ ohne WLS/Î») â†’ CLARIFY

Kunde â€œwÃ¼nscht DÃ¤mmstÃ¤rkeâ€ â†’ Agent liefert:

erforderliche Mindest-DÃ¤mmstÃ¤rke (aus Grenzwert rÃ¼ckwÃ¤rts gerechnet) als Vorschlag, aber markiert als â€Planungswert / BestÃ¤tigung nÃ¶tigâ€œ

3) Harte Abbruchkriterien (dein Sicherheitsmechanismus)
Ein Ergebnis darf nur PASS/FAIL werden, wenn:

Alle required_fields vorhanden sind oder Worst-Case-Garantie greift (Wand).

Jede Zahl hat Evidence (Textstelle/Seite/Positionszeile).

Keine Einheitenkonflikte (mm vs cm etc.).

Keine Mehrdeutigkeit bei Zuordnung (welcher Wert gehÃ¶rt zu welchem Bauteil).

Sonst immer: CLARIFY mit konkreten Fragen.

4) Kurz-Checkliste pro Bauteil (was der Agent â€brauchtâ€œ)
Fenster

Uw (Pflicht), Position/Typ

Dach

Schichten: d + Î» (Pflicht)

Bei Zwischensparren: Holzanteil (oder Sparrenbreite + Abstand)

Wand

Entweder U-Wert (Pflicht) oder neue DÃ¤mmung d + Î»

Wenn Worst-Case nicht reicht: Bestandsaufbau (grob reicht meist: Material + Dicke)

Wenn du willst, formatiere ich dir das jetzt als konkretes JSON-Schema (required_fields/abort_if_missing) fÃ¼r genau diese 3 Bauteile + eine Berechnungs-Policy (â€œwann rechnen erlaubt istâ€) â€“ damit du es 1:1 an einen Agenten/Workflow hÃ¤ngen kannst.


You said:
Wie fÃ¼rdest du die Anforderungen clustern/strukturiert auslesen?

ChatGPT said:

Thought for 40s
So wÃ¼rde ich es clustern und strukturiert auslesen, damit am Ende ein deterministisches Ruleset fÃ¼r â€fÃ¶rderfÃ¤hig / nicht fÃ¶rderfÃ¤hig / KlÃ¤rung nÃ¶tigâ€œ rausfÃ¤llt â€“ inkl. Tabellen/OCR/Evidence.

1) Erst clustern: Welche Dokumente liefern welche Art Anforderungen?
A. MaÃŸgeblich (Normativ)
BEG-EM-Richtlinie (21.12.2023, BAnz AT 29.12.2023 B1)
â†’ enthÃ¤lt die rechtlich maÃŸgeblichen Anforderungen, u. a. Definitionen, FÃ¶rdertatbestÃ¤nde und (entscheidend) die Technischen Mindestanforderungen (TMA) mit Grenzwerten (z. B. U-Werte) 

B. Operativ/Anwendungslogik (unterstÃ¼tzend, nicht maÃŸgeblich)
Allgemeines Merkblatt Antragstellung (Feb 2025)
â†’ Prozess/Unterlagen/Antragsschritte; es weist auch darauf hin, dass maÃŸgeblich die Richtlinie ist 

Infoblatt fÃ¶rderfÃ¤hige MaÃŸnahmen & Leistungen â€“ Sanieren (Stand 01.07.2025)
â†’ sehr wichtig fÃ¼r deinen Agenten, weil es MaÃŸnahmen-Katalog + (nicht) fÃ¶rderfÃ¤hige Kostenbestandteile systematisch auflistet 

C. Modul-fremd (fÃ¼r GebÃ¤udehÃ¼lle i. d. R. ausfiltern)
Merkblatt GebÃ¤udenetze 

Hydraulischer Abgleich (relevant fÃ¼r Heizung/Anlagentechnik, nicht GebÃ¤udehÃ¼lle) 

â†’ Die wÃ¼rde ich im System als separates Modul fÃ¼hren oder fÃ¼r den â€GebÃ¤udehÃ¼lle-Agentâ€œ komplett deaktivieren.

D. Bonus-Regeln (optional)
Zusatzantrag Einkommensbonus (eigener Block) 

2) Ziel-Cluster im Ruleset (so wÃ¼rde ich die Anforderungen sortieren)
Dein Agent braucht am Ende nicht â€Dokumentwissenâ€œ, sondern Regeltypen:

Scope & Eligibility (Geltungsbereich)

GebÃ¤udetyp/Bestand, Antragsteller, Kombinierbarkeit, AusschlÃ¼sse

Quelle: Richtlinie + Merkblatt-Antragstellung

MaÃŸnahmen-Katalog (Was ist grundsÃ¤tzlich fÃ¶rderfÃ¤hig?)

MaÃŸnahme â†’ Bauteilgruppe â†’ FÃ¶rdertatbestand

Quelle: Richtlinie + Infoblatt (als â€Katalogâ€œ)

Technische Mindestanforderungen (TMA / Grenzwerte)

z. B. Umax je Bauteil/Zonenfall, Uw bei Fenstern, SonderfÃ¤lle (InnendÃ¤mmung/Feuchte)

Quelle: Richtlinie/TMA

Kostenlogik (Was darf in die fÃ¶rderfÃ¤higen Kosten?)

fÃ¶rderfÃ¤hig / nicht fÃ¶rderfÃ¤hig / nur anteilig / Nebenleistungen

Quelle: Infoblatt 

Nachweise & Dokumentationspflichten

was muss im Angebot/Anlage/Nachweis stehen, Mindestangaben

Quelle: Merkblatt + Richtlinie

Abbruch-/KlÃ¤rungslogik (Fail-Safe)

required fields pro MaÃŸnahme

wenn fehlt â†’ â€œKLÃ„RUNGâ€, niemals raten

3) â€œStrukturiert auslesenâ€: Pipeline, die auch Tabellen/OCR sauber kann
Schritt 0: Dokument-Manifest + PrioritÃ¤ten
FÃ¼r jedes PDF:

doc_id, download_url, download_date, sha256, version_hint, priority

PrioritÃ¤t: Richtlinie > Infoblatt > MerkblÃ¤tter
(weil Merkblatt selbst sagt: maÃŸgeblich ist die Richtlinie) 

Schritt 1: Segmentierung nach Struktur (TOC/Ãœberschriften)
Aus jedem Dokument extrahierst du:

Ãœberschriftenhierarchie (Kapitel â†’ Unterkapitel)

Listen/Bullets

TabellenblÃ¶cke

DefinitionsblÃ¶cke (â€œBegriffsbestimmungenâ€)

Ergebnis: Chunks mit chunk_id, doc_id, page_range, heading_path.

Schritt 2: Kandidaten-Erkennung â€œRequirement Snippetsâ€
Du markierst Textstellen als Anforderungen anhand Muster:

MUSS/IST/VORAUSSETZUNG/DARF NICHT, Grenzwerte (â‰¤, >=), â€œnicht fÃ¶rderfÃ¤higâ€

Tabellenzeilen, die â€œBauteil â€“ Grenzwertâ€ enthalten

Kostenlisten â€œfÃ¶rderfÃ¤hig / nicht fÃ¶rderfÃ¤higâ€

Jeder Kandidat bekommt Evidence:

doc_id, page, quote (kurzer Text), ideal: bbox (Koordinaten)

Schritt 3: Tabellen-First bei TMA (wichtigster Teil)
FÃ¼r Seiten mit U-Wert/Uw-Tabellen:

Tabellenextraktion (Zellen â†’ Zeilenobjekte)

Normalisierung:

Dezimalkomma â†’ Zahl

Einheitenvarianten â†’ Canonical Einheit

Jede Tabellenzeile wird ein Requirement-Record

Wenn Tabellenextraktion scheitert:

OCR nur fÃ¼r die betroffenen Seiten

Evidence bleibt: page + quote (+ bbox wenn mÃ¶glich)

Schritt 4: Normalisierung in ein kontrolliertes Vokabular
Du mappst Begriffe auf feste Keys:

â€œFassade/WDVS/AuÃŸenwandâ€ â†’ component_type="AuÃŸenwand"

â€œDach/Steildach/Flachdach/oberste Geschossdeckeâ€ â†’ klare Typen

Kostenarten: GerÃ¼st, Putz, Entsorgung, Planung usw.

Schritt 5: â€œRequirement-Recordâ€ bauen (dein Zwischenformat)
Das ist der wichtigste Schritt: aus Text/Tabellen wird ein normiertes Objekt:

{
  "req_id": "tma_u_auÃŸenwand_zoneA",
  "req_type": "TECH_THRESHOLD",
  "scope": {"module":"GebÃ¤udehÃ¼lle","component":"AuÃŸenwand","case":"beheizt"},
  "fields": [{"name":"u_value_target","op":"<=","value":0.20,"unit":"W/(mÂ²K)"}],
  "source_priority": 100,
  "evidence": [{"doc_id":"beg_em_richtlinie_2023-12-21","page":18,"quote":"AuÃŸenwand â€¦ 0,20"}]
}
Schritt 6: Aus Requirement-Records wird das Ruleset (Entscheidungsgrundlage)
Jetzt â€œkompilierstâ€ du:

pro MaÃŸnahme ein Rule Template:

required_fields

pass_conditions (aus TECH_THRESHOLD + ELIGIBILITY)

fail_conditions (explizite AusschlÃ¼sse)

clarify_conditions (wenn required fehlt)

4) Minimale â€œFail-Safeâ€-Regeln beim Auslesen (gegen LLM/Extraktionsfehler)
Jede Zahl im Ruleset muss evidence-gebunden sein (quote muss vorkommen).

Konfliktregel: Wenn zwei Dokumente widersprechen â†’ nimm hÃ¶chste PrioritÃ¤t (Richtlinie), lagere den Rest als Kommentar aus. 

Coverage-Check: FÃ¼r GebÃ¤udehÃ¼lle mÃ¼ssen Regeln existieren fÃ¼r:

AuÃŸenwand, Dach/OGD, Kellerdecke/Boden, Fenster/TÃ¼ren, SonderfÃ¤lle (z. B. InnendÃ¤mmung)

Wenn Coverage nicht erfÃ¼llt â†’ Ruleset nicht freigeben (Abbruch).

5) Ergebnis: Was du danach â€œin den Agent Contextâ€ gibst
Nicht die PDFs, sondern:

ruleset.json (kompiliert, deterministisch)

evidence_store (Zitat + Seite + bbox/Screenshot)

optional guidance aus Infoblatt/Merkblatt (Kosten-/Prozesshinweise) 

Wenn du magst, kann ich dir als nÃ¤chstes ein konkretes Cluster-Schema fÃ¼r GebÃ¤udehÃ¼lle liefern (AuÃŸenwand/Dach/Fenster) inklusive:

required_fields je Bauteil

â€œU-Wert direktâ€ vs â€œSchichtenrechnungâ€ vs â€œWorst-Case-Garantieâ€

und die Standard-KlÃ¤rungsfragen, die deine SekretÃ¤rin dann 1:1 an Kunden schicken kann.


You said:
Erstelle eine spec structur was fÃ¼r alle fÃ¶rderungsmaÃŸnahmen passt

ChatGPT said:

Thought for 13s
Unten ist eine universelle Spec-Struktur, die fÃ¼r alle BEG/BAFA-FÃ¶rdermaÃŸnahmen taugt (GebÃ¤udehÃ¼lle, Fenster, Dach, Heizungstausch, Optimierung, LÃ¼ftung, ggf. Boni, Kostenlogik, Nachweise). Sie ist so gebaut, dass dein Agent nicht raten muss, sondern deterministisch entscheiden kann â€“ und du trotzdem Evidence + Auditing hast.

0) Prinzip: 3 Artefakte statt â€ein JSON fÃ¼r allesâ€œ
offer_facts.json (aus Angebot/AnhÃ¤ngen extrahierte Fakten + Evidence)

ruleset.json (aus Richtlinie/InfoblÃ¤ttern kompiliert: MaÃŸnahmen + Anforderungen + Kostenlogik)

evaluation.json (Ergebnis je MaÃŸnahme: PASS/FAIL/CLARIFY + BegrÃ¼ndung + Kundenfragen)

Damit trennst du: Was steht drin? vs. Was gilt? vs. Was ist das Ergebnis?

1) Universelle DSL fÃ¼r Bedingungen (Condition)
Diese Condition-Form funktioniert Ã¼berall (U-Wert, Uw, Jahresarbeitszahl, hydraulischer Abgleich, FachunternehmererklÃ¤rung, Kombinationsregeln etc.):

{
  "field": "offer.u_value_target",
  "op": "<=",
  "value": 0.20,
  "unit": "W/(mÂ²K)",
  "evidence_required": true,
  "severity_if_missing": "CLARIFY"
}
Erweiterungen:

value_from: Grenzwert aus Tabelle ziehen (statt hart codiert)

any_of / all_of / not

depends_on: nur prÃ¼fen wenn MaÃŸnahmetyp/Unterfall zutrifft

2) Universelle MaÃŸnahme-Spec (gilt fÃ¼r alle FÃ¶rdermaÃŸnahmen)
MeasureSpec (Template)
{
  "measure_id": "beg_em.envelope.wall.insulation",
  "module": "Gebaeudehuelle",
  "title": "Daemmung Aussenwand",
  "version": "2026-02-15",
  "legal_basis": [
    {"doc_id": "beg_em_richtlinie", "section": "TMA", "priority": 100}
  ],

  "scope": {
    "building_types": ["WG", "NWG"],
    "requires_existing_building": true,
    "excludes_new_build": true
  },

  "required_fields": [
    {"path": "offer.component_type", "severity_if_missing": "ABORT"},
    {"path": "offer.costs.total", "severity_if_missing": "CLARIFY"}
  ],

  "eligibility": {
    "all_of": [
      {"field": "building.is_existing", "op": "==", "value": true},
      {"field": "offer.component_type", "op": "==", "value": "AuÃŸenwand"}
    ],
    "any_of": [],
    "exclusions": [
      {
        "when_all_of": [
          {"field": "offer.is_internal_insulation", "op": "==", "value": true},
          {"field": "docs.tauwassernachweis_present", "op": "==", "value": false}
        ],
        "result": "CLARIFY",
        "message_key": "need_condensation_proof"
      }
    ]
  },

  "technical_requirements": {
    "thresholds": [
      {
        "name": "u_max",
        "condition": {
          "field": "derived.u_value_target",
          "op": "<=",
          "value_from": "tables.tma.u_max.by_component_and_zone",
          "unit": "W/(mÂ²K)",
          "evidence_required": true,
          "severity_if_missing": "CLARIFY"
        }
      }
    ],
    "calculation_methods": [
      {
        "method_id": "uvalue_from_layers",
        "when_all_of": [{"field": "offer.input_mode", "op": "==", "value": "layers"}],
        "inputs": ["offer.layers[].d_m", "offer.layers[].lambda"],
        "outputs": ["derived.u_value_target"],
        "abort_if_missing": ["offer.layers"]
      }
    ]
  },

  "cost_rules": {
    "eligible_cost_categories": ["Material", "Montage", "Nebenarbeiten_notwendig"],
    "ineligible_cost_categories": ["Finanzierung", "Wartung", "Eigenleistung"],
    "split_rules": [
      {
        "when": {"field": "offer.line_items[].type", "op": "==", "value": "Geruest"},
        "result": "ELIGIBLE_IF_NECESSARY",
        "note_key": "scaffolding_if_necessary"
      }
    ]
  },

  "documentation": {
    "must_have": [
      {"doc": "Fachunternehmererklaerung", "severity_if_missing": "CLARIFY"},
      {"doc": "Uwert_Nachweis_or_Layers", "severity_if_missing": "CLARIFY"}
    ],
    "nice_to_have": []
  },

  "outputs": {
    "messages": {
      "pass_summary_key": "pass_wall_insulation",
      "clarify_questions_keys": ["ask_wall_build_up", "ask_lambda_thickness"]
    }
  },

  "examples": {
    "eligible": [{"facts_ref": "tests/wall_ok_01.json", "expected": "PASS"}],
    "not_eligible": [{"facts_ref": "tests/wall_fail_01.json", "expected": "FAIL"}],
    "clarify": [{"facts_ref": "tests/wall_missing_u_01.json", "expected": "CLARIFY"}]
  }
}
Warum das fÃ¼r alles passt:

scope deckt FÃ¶rderfÃ¤higkeitsrahmen ab

required_fields + severity_if_missing ist dein Fail-Safe

technical_requirements.thresholds kann U-Werte, Uw, Wirkungsgrade, Nachweise, Verfahrensanforderungen usw. abbilden

cost_rules trennt fÃ¶rderfÃ¤hige/nicht fÃ¶rderfÃ¤hige Kosten (sehr wichtig)

documentation.must_have erzwingt Nachweise

examples werden zu Regression-Tests

3) Tabellen-/Grenzwert-Referenzen (ohne harte Werte im Code)
Statt Ã¼berall 0.20 einzubauen, nutzt du Tabellen-Lookups:

"tables": {
  "tma": {
    "u_max": {
      "by_component_and_zone": [
        {"component":"AuÃŸenwand","zone":"WG_T>=19","u_max":0.20,"evidence":{...}},
        {"component":"Dach","zone":"WG_T>=19","u_max":0.14,"evidence":{...}}
      ]
    }
  }
}
Vorteil: Wenn BAFA etwas Ã¤ndert, update nur die Tabelle + Evidence.

4) Universal offer_facts.json (damit alle MaÃŸnahmen abgedeckt sind)
{
  "building": {
    "is_existing": true,
    "type": "WG",
    "location_plz": "60311",
    "monument": false
  },
  "applicant": {
    "income_bonus_requested": false
  },
  "offer": {
    "input_mode": "direct_u_or_layers",
    "measures": [
      {
        "component_type": "Fenster",
        "values": {"uw": {"value": 0.9, "unit": "W/(mÂ²K)", "evidence": {...}}},
        "costs": {"total": 12000, "currency": "EUR"},
        "line_items": [...]
      },
      {
        "component_type": "Dach",
        "values": {},
        "layers": [
          {"d_m": 0.16, "lambda": 0.035, "evidence": {...}},
          {"d_m": 0.10, "lambda": 0.044, "evidence": {...}}
        ],
        "geometry": {"wood_fraction": null},
        "costs": {"total": 18000, "currency": "EUR"}
      }
    ]
  },
  "docs": {
    "fachunternehmererklaerung_present": false,
    "tauwassernachweis_present": null
  }
}
5) Universal evaluation.json (fÃ¼r SekretÃ¤rin + Kundenmail)
{
  "case_id": "2026-02-15_001",
  "results": [
    {
      "measure_id": "beg_em.envelope.window.replace",
      "status": "PASS",
      "reason": "Uw <= Grenzwert",
      "used_evidence": [{"doc_id":"offer_pdf","page":2,"quote":"Uw = 0,90 W/mÂ²K"}],
      "customer_message": "Die Fenster (Uw 0,90) sind nach aktueller Datenlage fÃ¶rderfÃ¤hig."
    },
    {
      "measure_id": "beg_em.envelope.roof.insulation",
      "status": "CLARIFY",
      "reason": "Holzanteil/Sparrenangaben fehlen",
      "questions": [
        "Bitte Sparrenbreite und Sparrenabstand (AchsmaÃŸ) angeben.",
        "Alternativ: U-Wert-Nachweis nach Sanierung beilegen."
      ]
    }
  ]
}
6) Minimal-Regeln, die du immer brauchst (fÃ¼r alle MaÃŸnahmen)
No-Guess Policy: fehlende Muss-Felder â†’ niemals PASS/FAIL, sondern CLARIFY/ABORT

Evidence Pflicht: jede Zahl/Schwelle braucht Quelle (Seite/Quote/bbox)

PrioritÃ¤tenmodell: Richtlinie/TMA schlÃ¤gt Merkblatt/Infoblatt bei Konflikten

Coverage Check: Ruleset darf nur live gehen, wenn alle Module deiner Firma abgedeckt sind

Wenn du willst, mache ich dir als nÃ¤chsten Schritt eine komplette â€œMeasure Libraryâ€ als leere Templates (GebÃ¤udehÃ¼lle, Heizung, Optimierung, LÃ¼ftung etc.) mit:

empfohlenen required_fields pro Modul

typischen documentation.must_have

Standard-KlÃ¤rungsfragen-Keys (deutsch, fÃ¼r SekretÃ¤rin/Kundenmail)


You said:
welches llm wÃ¼rdest du mir empfehlen?

ChatGPT said:

Thought for 1m 17s
FÃ¼r deinen BAFA/BEG-PrÃ¼f-Agent (Angebot rein â†’ fÃ¶rderfÃ¤hig/unklar/nicht raus + Kundenmail) wÃ¼rde ich eine Modell-Kaskade empfehlen â€“ nicht â€ein einziges LLM fÃ¼r allesâ€œ.

Empfehlung (praxisnah)
1) Standard-Arbeit (80â€“90% der FÃ¤lle)
OpenAI GPT-5 mini als Default-Modell fÃ¼r

Fakten-Extraktion aus Angebot (Positionen, Bauteil, Dicken, Î», Uw, Kosten)

Mail-/Memo-Texte fÃ¼r SekretÃ¤rin/Kunde

â€œTriageâ€ (ist alles vollstÃ¤ndig oder KlÃ¤rungsfall?)

GPT-5 mini ist explizit als schnelle, kosteneffiziente Variante fÃ¼r klar definierte Tasks gelistet. 

2) Eskalation bei kniffligen FÃ¤llen (10â€“20%)
OpenAI GPT-5.2 (oder GPT-5.2 pro) nur dann, wenn

Tabellen/Positionen widersprÃ¼chlich sind

Bauteil-Zuordnung unklar (z. B. OGD vs Dach, Innen- vs AuÃŸendÃ¤mmung)

du eine â€œSecond opinionâ€ brauchst

GPT-5.2 (und â€proâ€œ) ist in der Modellliste als stÃ¤rkstes Modell fÃ¼r agentische/komplexe Aufgaben beschrieben. 

Warum diese Kombi fÃ¼r dich besonders gut passt
A) Du willst garantiertes JSON, nicht â€œbest effortâ€
Nutze Structured Outputs mit JSON-Schema (Responses API), dann hÃ¤lt das Modell dein Schema zuverlÃ¤ssig ein (keine fehlenden Keys, keine falschen Enums). 

Wichtig fÃ¼r dich: Das verhindert Format-Fehler â€“ nicht automatisch Inhalts-Fehler. Deshalb die Kaskade + Rule-Engine.

B) Vision/Scan-PDFs: nicht alles in einen Call quetschen
OpenAI weist explizit darauf hin, dass Structured Outputs in der Assistants API bei Vision nicht unterstÃ¼tzt sind. 

Praktisch heiÃŸt das:

Scan-PDF â†’ OCR / Text-Extraktion â†’ dann Structured Output (JSON)
oder

Vision-Call â†’ Text/Key-Values â†’ dann zweiter Call â€œstrict JSONâ€

Damit bleibt dein Output stabil.

â€œWenn du alles in-house willstâ€
Als Alternative gibtâ€™s open-weight Modelle (z. B. gpt-oss-20b/120b) â€“ gut fÃ¼r Datenschutz/On-Prem, aber du brauchst GPU-Infra + mehr Engineering. 

FÃ¼r einen schnellen Start und 10 PrÃ¼fungen/Tag ist OpenAI-Kaskade meist deutlich effizienter.

Kurz: Was ich dir konkret empfehlen wÃ¼rde
Default: GPT-5 mini

Eskalation: GPT-5.2 (oder 5.2 pro)

Format-Sicherheit: Responses API + Structured Outputs (JSON-Schema) 

Fehler-Sicherheit: Entscheidung immer durch deine deterministische Rule-Engine, LLM nur fÃ¼r Extraktion/BegrÃ¼ndung.

Wenn du willst, schreibe ich dir als nÃ¤chstes eine konkrete â€Model Routingâ€œ-Policy (wann mini, wann 5.2) + ein JSON-Schema fÃ¼r offer_facts (Fenster/Uw, Dach/Schichten, Wand/Worst-Case-Garantie).


You said:
wie werden dann die rules extrahiert?

ChatGPT said:

Thought for 8s
Gute Frage â€“ und wichtig: Die Rules werden nicht â€œeinfach vom LLM aus dem PDF rausgelesenâ€ (zu fehleranfÃ¤llig), sondern Ã¼ber eine Pipeline, in der das LLM nur klassifiziert/zuordnet, wÃ¤hrend Zahlen/Grenzwerte tabellenbasiert + evidence-gebunden Ã¼bernommen werden.

Hier ist die robuste Logik, wie du aus deinen BAFA/BEG-PDFs ein ruleset.json erzeugst.

Ziel: Aus PDFs â†’ RequirementRecords â†’ kompiliertes ruleset.json
Ergebnisformate
evidence_store: extrahierte Textzeilen + Tabellen + OCR + Screenshots (mit Seite/BBox)

requirements.jsonl: atomare Anforderungen (ein Grenzwert / ein Ausschluss / ein Nachweis)

ruleset.json: pro MaÃŸnahme ein â€MeasureSpecâ€œ mit required_fields, conditions, cost_rules, docs

Schritt 1 â€“ Dokument-Manifest & Versionierung (damit Updates sauber sind)
FÃ¼r jedes PDF:

doc_id, download_url, download_date

sha256 (Hash der Datei)

title, version_hint (sofern im PDF sichtbar)

â¡ï¸ Nur wenn Hash neu â†’ neu extrahieren.

Schritt 2 â€“ PDF â€Layout-Extraktionâ€œ (Text + Koordinaten)
Du extrahierst Zeilen mit Position:

page, x0,y0,x1,y1, text

Warum Koordinaten?
Damit du spÃ¤ter Evidence sauber referenzierst (â€steht wirklich daâ€œ).

QualitÃ¤tscheck:

Wenn kaum Text extrahierbar (Scan) â†’ OCR-Fallback pro Seite.

Schritt 3 â€“ Tabellen-Extraktion (kritisch: TMA / Grenzwerttabellen)
FÃ¼r Seiten, die Tabellen enthalten (typisch: U-Werte, Uw-Grenzen, ggf. Wirkungsgrade etc.):

Tabellenregion erkennen (BBox)

Zellen extrahieren â†’ cells[r][c]

Normalisieren:

0,20 â†’ 0.20 (Wert)

Originalstring bleibt im Evidence (â€0,20â€œ)

Einheiten vereinheitlichen

â¡ï¸ Diese Tabellen liefern die â€œharten Zahlenâ€.
Wenn Tabellenextraktion scheitert: OCR gezielt nur auf den Tabellenseiten.

Schritt 4 â€“ Kandidaten finden: â€œRequirement Snippetsâ€
Jetzt markierst du Textstellen als potenzielle Anforderungen.

Heuristiken (deterministisch):

SchlÃ¼sselwÃ¶rter: muss / darf nicht / Voraussetzung / fÃ¶rderfÃ¤hig / nicht fÃ¶rderfÃ¤hig

Operatoren: <=, â‰¥, %, W/mÂ²K

ListenblÃ¶cke (AufzÃ¤hlungen) fÃ¼r Kosten/Nachweise

Tabellenzeilen mit Bauteil + Zahl

Output: snippet-Objekte mit Evidence:

doc_id, page, quote, bbox, type (table_row / bullet / paragraph)

Schritt 5 â€“ LLM nur fÃ¼r Struktur & Mapping (nicht fÃ¼r Zahlen erfinden)
Jetzt kommt das LLM â€“ aber in einer sehr engen Rolle:

Aufgabe A: Klassifizieren
FÃ¼r jeden Snippet:

req_type: TECH_THRESHOLD | DOC_REQUIREMENT | COST_ELIGIBILITY | EXCLUSION | PROCESS_RULE

module: GebÃ¤udehÃ¼lle / Heizung / Optimierung / Bonus / â€¦

measure_id (ZielmaÃŸnahme)

Aufgabe B: EntitÃ¤ten mappen
Begriffe aus Text werden auf kontrollierte Keys gemappt:

â€Fassadeâ€œ, â€WDVSâ€œ â†’ component_type=AuÃŸenwand

â€oberste Geschossdeckeâ€œ â‰  â€DachflÃ¤cheâ€œ (separat!)

â€Uwâ€œ vs â€Ugâ€œ

Wichtig: Zahlen/Grenzwerte kommen bei Tabellen aus der Tabelle, nicht aus LLM-Paraphrasen.

Schritt 6 â€“ Atomare â€œRequirementRecordsâ€ bauen (dein Zwischenformat)
Aus jedem Snippet entsteht ein standardisiertes Objekt:

Beispiel: technischer Grenzwert

{
  "req_id": "tma.u_max.wall.zone_wg_tge19",
  "req_type": "TECH_THRESHOLD",
  "scope": {"module":"GebÃ¤udehÃ¼lle","measure":"AuÃŸenwanddÃ¤mmung","component":"AuÃŸenwand","case":"WG_T>=19"},
  "rule": {"field":"derived.u_value_target","op":"<=","value":0.20,"unit":"W/(mÂ²K)"},
  "evidence": [{"doc_id":"beg_em_richtlinie","page":18,"quote":"AuÃŸenwand â€¦ 0,20","bbox":[...]}],
  "priority": 100
}
Beispiel: Nachweis

{
  "req_type":"DOC_REQUIREMENT",
  "scope":{"module":"GebÃ¤udehÃ¼lle","measure":"InnendÃ¤mmung"},
  "rule":{"field":"docs.tauwassernachweis_present","op":"==","value":true},
  "severity_if_missing":"CLARIFY",
  "evidence":[...],
  "priority": 100
}
Beispiel: Kostenregel

{
  "req_type":"COST_ELIGIBILITY",
  "scope":{"module":"GebÃ¤udehÃ¼lle","measure":"AuÃŸenwanddÃ¤mmung"},
  "cost_category":"GerÃ¼st",
  "decision":"ELIGIBLE_IF_NECESSARY",
  "evidence":[...],
  "priority": 80
}
Schritt 7 â€“ Kompilieren zu â€œMeasureSpecâ€ (Ruleset)
Jetzt â€œkompiliertâ€ ein deterministischer Builder aus vielen RequirementRecords eine MaÃŸnahme:

required_fields (was muss im Angebot stehen?)

eligibility (Scope-Regeln)

technical_requirements.thresholds (Grenzwerte)

documentation.must_have

cost_rules

â¡ï¸ Das ist genau das Spec-Format, das du vorhin wolltest.

Schritt 8 â€“ Guards (damit du dem System vertrauen kannst)
Das ist der Teil, der dich vor LLM-Fehlern schÃ¼tzt:

Guard 1: Evidence-Binding
Jeder Grenzwert muss:

im Evidence-Quote vorkommen und

aus Tabelle/OCR/Text extrahiert sein (nicht â€œnur LLMâ€)

Wenn nicht: Rule wird verworfen â†’ â€œRuleset incompleteâ€.

Guard 2: KonfliktauflÃ¶sung nach PrioritÃ¤t
Wenn Infoblatt und Richtlinie widersprechen:

Richtlinie gewinnt, Infoblatt wird nur als Guidance gespeichert.

Guard 3: Coverage-Check
FÃ¼r jedes aktivierte Modul mÃ¼ssen Mindest-Sets existieren:

GebÃ¤udehÃ¼lle: AuÃŸenwand / Dach / Decken / Fenster-TÃ¼ren (+ SonderfÃ¤lle)

Heizung: Erzeuger / Optimierung / Nachweise / AusschlÃ¼sse
Wenn nicht erfÃ¼llt â†’ Ruleset nicht freigeben.

Guard 4: Diff-Alarm bei Updates
Wenn neue PDF-Version â†’ Builder zeigt:

welche Grenzwerte sich Ã¤ndern

welche Regeln neu/wegfallen
Dann kannst du (oder jemand intern) einmal kurz reviewen.

Was bedeutet das praktisch fÃ¼r dich (Dennis)?
Einmal baust du die Mapping-/Template-Schicht (Measure IDs, Bauteil-Taxonomie).

Danach laufen Updates sehr stabil, weil das System nur evidence-gebundene Regeln akzeptiert.

Wenn du mir sagst, ob du das in Zoho/Deluge, Node/Python, oder Make/Zapier + Server umsetzen willst, gebe ich dir als nÃ¤chstes:

das komplette requirements.jsonl Schema +

ein konkretes MeasureSpec-Template fÃ¼r alle Module (GebÃ¤udehÃ¼lle/Heizung/Optimierung/LÃ¼ftung/Bonus) inkl. required_fields und Standard-Guards.


You said:
in welchem Format liegen dann die rules vor? in einer json file oder mehrere? 

ChatGPT said:
Ich wÃ¼rde sie nicht in eine einzige JSON packen, sondern mehrteilig und versioniert â€“ so bleibtâ€™s wartbar, update-sicher und du kannst einzelne Module austauschen (z. B. GebÃ¤udehÃ¼lle vs. Heizung).

âœ… Empfohlenes Format-Set (in der Praxis bewÃ¤hrt)
1) manifest.json (1 Datei)
EnthÃ¤lt Version/Hash/Quelle der PDFs + Build-Metadaten.

Vorteil: Du kannst immer nachweisen, gegen welche Dokumentversion geprÃ¼ft wurde.

2) tables/*.json (mehrere Dateien)
Alle tabellarischen Grenzwerte (z. B. Umax, Uw-Grenzen, Wirkungsgrade) als saubere Tabellenobjekte.

z. B. tables/tma_u_values.json

z. B. tables/window_uw_thresholds.json

Vorteil: Ã„nderungen betreffen nur eine Tabelle, nicht das ganze Ruleset.

3) measures/*.json (mehrere Dateien, pro MaÃŸnahme oder pro Modul)
Je MaÃŸnahme ein MeasureSpec (dein â€œRegelpaketâ€ inkl. required_fields, conditions, docs, cost rules).

z. B. measures/envelope_wall_insulation.json

z. b. measures/envelope_roof_insulation.json

z. b. measures/heating_heatpump.json

4) taxonomy/*.json (1â€“3 Dateien)
Kontrolliertes Vokabular + Synonyme (damit â€œWDVS/Fassade/AuÃŸenwandâ€ sauber gemappt wird).

z. B. taxonomy/components.json

z. b. taxonomy/cost_categories.json

5) evidence_store/ (viele kleine Dateien)
Evidence als Textchunks + (optional) Screenshots/Bounding Boxes pro Regel/Tabellenzeile.

z. B. evidence_store/beg_em_richtlinie/page18_table1_row3.json

Vorteil: Du kannst jede Regel auditieren (â€œwo steht das?â€).

Wie wird das im Betrieb genutzt?
Option A (empfohlen): Viele Dateien als Source-of-Truth
Dein Build-Prozess lÃ¤dt + extrahiert + kompiliert und legt alles in Ordnern ab.

Option B: Ein â€Bundleâ€œ fÃ¼r Deployment
FÃ¼r Laufzeit (Agent) kann man zusÃ¤tzlich ein kompaktes Bundle erzeugen:

ruleset.bundle.json (1 Datei)

enthÃ¤lt: measures + tables + taxonomy (ohne groÃŸe Evidence-Dateien)

Evidence bleibt separat, wird nur bei Bedarf nachgeladen

â¡ï¸ Best of both worlds: wartbar + schnell.

Konkrete Empfehlung fÃ¼r dich (BAFA/BEG Agent)
Im Repo/Storage (Wartung):

mehrere JSON-Dateien (Modular)

Im Agent zur Laufzeit (Performance):

1 Bundle JSON (schnell laden)

Evidence separat (nur bei Debug/BegrÃ¼ndung)

Beispiel: Ordnerstruktur (ready-to-implement)
rules/
  manifest.json
  taxonomy/
    components.json
    measures.json
    cost_categories.json
  tables/
    tma_u_values.json
    window_thresholds.json
  measures/
    envelope_wall_insulation.json
    envelope_roof_insulation.json
    envelope_windows.json
    heating_heatpump.json
  evidence_store/
    beg_em_richtlinie/
      page_18_table_uvalues_row_03.json
      ...
  bundles/
    ruleset.bundle.json
Wenn du willst, kann ich dir als nÃ¤chstes ein konkretes, sauberes JSON-Schema fÃ¼r:

MeasureSpec

TableSpec

EvidenceRef

RulesetBundle

geben, sodass dein Entwickler das 1:1 implementieren kann.


You said:
Wie lÃ¤uft dann der Prozess ab

=> Angebot => prÃ¼fen ob fÃ¶rderfÃ¤hig

ChatGPT said:

Thought for 9s
So lÃ¤uft der Prozess in der Praxis ab (vom Angebot bis fÃ¶rderfÃ¤hig / nicht fÃ¶rderfÃ¤hig / KlÃ¤rung). Ich beschreibe das so, dass du es 1:1 als Workflow fÃ¼r eure 10/Tag nutzen kannst.

0) Vorarbeit (lÃ¤uft automatisch tÃ¤glich)
Rules-Update Job

BAFA/BEG-PDFs laden (Version/Hash speichern)

Tabellen & Anforderungen extrahieren â†’ tables/*.json, measures/*.json

Guard-Checks:

Evidence vorhanden?

Coverage vollstÃ¤ndig?

Konflikte? (Richtlinie > Merkblatt/Infoblatt)

Ergebnis: ruleset.bundle.json (fÃ¼r schnelle Laufzeit) + evidence_store/

Wenn Guard scheitert â†’ Ruleset nicht aktivieren (Fail-Safe).

1) Eingang: Angebot rein
Input

Angebot (PDF/DOCX/Emailtext) + ggf. AnhÃ¤nge (Produktdaten, U-Wert-Nachweise)

Preflight

Case-ID vergeben

Dokumenttyp erkennen:

Text-PDF â†’ Text/Layout-Extraktion

Scan-PDF â†’ OCR

QualitÃ¤tsflag setzen (z. B. â€œTabellen schwer lesbarâ€)

2) Angebots-Parsing â†’ â€œMaÃŸnahmenobjekteâ€
Ziel: aus dem Angebot eine Liste von MaÃŸnahmen bauen:

Beispiele:

Fenster (Uw)

Dach (Schichten Î»+d, ggf. Sparren)

AuÃŸenwand (DÃ¤mmstÃ¤rke/Î» oder Ziel-U)

Kellerdecke / Bodenplatte etc.

Dabei wird gemappt auf euer kontrolliertes Vokabular:

â€œWDVS/Fassadeâ€ â†’ AuÃŸenwand

â€œDach/OGDâ€ sauber trennen

Kostenpositionen clustern (Material/Montage/GerÃ¼st/Entsorgung â€¦)

3) Fakten-Extraktion â†’ offer_facts.json (strict)
Hier arbeitet das LLM nur als Extraktor, nicht als Entscheider.

Wichtig: Jede Zahl braucht Evidence (Seite + Textsnippet/Zeile).

Fenster: uw (fast immer direkt)

Dach: layers[] (d + Î») oder u_value_target

Wand: u_value_target oder new_insulation (d+Î») + ggf. â€œBestand unbekanntâ€

Dann:

JSON-Schema Validierung (hart)

Wenn Schema/Evidence fehlt â†’ CLARIFY/ABORT (nicht â€œratenâ€).

4) Ableitungen (deterministisch, kein LLM)
Aus offer_facts werden derived values berechnet:

Fenster: derived.uw = offer.uw

Dach:

wenn nur Schichten: U-Wert rechnen

bei Zwischensparren: Bandbreite f=0.07/0.10/0.15

wenn selbst bei 0.15 ok â†’ PASS mÃ¶glich

wenn selbst bei 0.07 fail â†’ FAIL mÃ¶glich

sonst â†’ CLARIFY (Sparrenangaben)

Wand:

wenn Bestand unklar: Worst-Case ohne Bestandswiderstand

wenn Worst-Case schon <= Grenzwert â†’ PASS mÃ¶glich

sonst â†’ CLARIFY (Bestandsaufbau oder mehr DÃ¤mmung)

Alles landet in derived.* (mit Vermerk â€œberechnetâ€ + Inputs).

5) RegelprÃ¼fung (Rule Engine) â†’ evaluation.json
Jetzt kommt das Ruleset ins Spiel.

FÃ¼r jede MaÃŸnahme:

passendes MeasureSpec finden (z. B. envelope_wall_insulation)

required_fields prÃ¼fen

fehlt etwas Relevantes â†’ CLARIFY (mit konkreten Fragen)

eligibility/scope prÃ¼fen (Bestand? MaÃŸnahmetyp korrekt?)

technical thresholds prÃ¼fen (Umax/Uw etc.)

exclusions prÃ¼fen (z. B. InnendÃ¤mmung ohne Nachweis â†’ CLARIFY/FAIL je Regel)

Ergebnis je MaÃŸnahme:

PASS (fÃ¶rderfÃ¤hig)

FAIL (nicht fÃ¶rderfÃ¤hig)

CLARIFY (nicht eindeutig / Unterlagen fehlen)

6) Kostenlogik (separat!)
UnabhÃ¤ngig von â€œtechnisch fÃ¶rderfÃ¤higâ€ wird die Kostenliste geprÃ¼ft:

fÃ¶rderfÃ¤hige Kosten

nicht fÃ¶rderfÃ¤hige Kosten

bedingt/anteilig (z. B. GerÃ¼st nur wenn notwendig)

Output:

fÃ¶rderfÃ¤hige Kostensumme + Hinweise, welche Positionen problematisch sind

7) Output fÃ¼r SekretÃ¤rin + Kundenmail-Entwurf
SekretÃ¤rinnen-Memo (intern)

Ampel je MaÃŸnahme (PASS/FAIL/CLARIFY)

fehlende Unterlagen als Checkliste

ggf. â€œMinimalinfos anfordernâ€-Textbausteine

Kundenmail (extern)

nur sichere Aussagen

bei CLARIFY: konkrete Nachforderungsliste

optional: Hinweis â€œVorprÃ¼fung auf Basis der vorliegenden Angabenâ€

8) Logging / Audit / Eskalation
Alles wird gespeichert: Angebot â†’ offer_facts â†’ derived â†’ evaluation (mit Evidence)

Eskalation an Dennis/Experten nur wenn:

CLARIFY mit hoher Relevanz

widersprÃ¼chliche Angaben

TextqualitÃ¤t schlecht (OCR unsicher)

Mini-Beispiel (typisch)
Dach mit Schichten, aber Sparren unbekannt

Facts ok, Schichten ok

derived: U-Bandbreite

Ergebnis:

wenn Bandbreite eindeutig ok â†’ PASS

sonst â†’ CLARIFY: â€œSparrenbreite + Achsabstand oder U-Wert-Nachweis nachreichenâ€

Wenn du mir sagst, wo das Angebot bei euch ankommt (Zoho CRM, Gmail, Drive, Upload-Formular), dann gebe ich dir den Prozess als konkrete Automations-Kette (Trigger â†’ Steps â†’ Outputs) passend zu eurem Stack.




